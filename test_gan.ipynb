{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from train_gan import (\n",
    "    Critic,\n",
    "    EuXFELCurrentDataModule,\n",
    "    EuXFELCurrentDataset,\n",
    "    Generator,\n",
    "    ConvolutionalDecoder,\n",
    "    ConvolutionalEncoder,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalEncoder(\n",
       "  (convnet): Sequential(\n",
       "    (0): Conv1d(1, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=960, out_features=100, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formfactor_encoder = ConvolutionalEncoder(signal_dims=240, latent_dims=10)\n",
    "formfactor_encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded = tensor([[-0.0393,  0.0811,  0.1199,  0.0599, -0.0660,  0.0160, -0.1065, -0.0042,\n",
      "          0.1152, -0.1126],\n",
      "        [-0.0406,  0.0854,  0.1207,  0.0606, -0.0653,  0.0146, -0.1049, -0.0053,\n",
      "          0.1116, -0.1091],\n",
      "        [-0.0426,  0.0803,  0.1253,  0.0619, -0.0626,  0.0149, -0.1068, -0.0015,\n",
      "          0.1141, -0.1099]], grad_fn=<AddmmBackward0>)\n",
      "encoded.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "formfactor = torch.rand(3, 240)\n",
    "encoded = formfactor_encoder(formfactor)\n",
    "print(f\"{encoded = }\")\n",
    "print(f\"{encoded.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalEncoder(\n",
       "  (convnet): Sequential(\n",
       "    (0): Conv1d(1, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=1216, out_features=100, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_encoder = ConvolutionalEncoder(signal_dims=300, latent_dims=10)\n",
    "current_encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded = tensor([[-0.0733,  0.0361,  0.0691, -0.1389, -0.0472, -0.0301,  0.0685,  0.1085,\n",
      "         -0.0122, -0.0509],\n",
      "        [-0.0738,  0.0387,  0.0680, -0.1381, -0.0491, -0.0315,  0.0672,  0.1079,\n",
      "         -0.0128, -0.0521],\n",
      "        [-0.0738,  0.0409,  0.0709, -0.1325, -0.0459, -0.0315,  0.0656,  0.1074,\n",
      "         -0.0132, -0.0517]], grad_fn=<AddmmBackward0>)\n",
      "encoded.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "current_profile = torch.rand(3, 300)\n",
    "encoded = current_encoder(current_profile)\n",
    "print(f\"{encoded = }\")\n",
    "print(f\"{encoded.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalDecoder(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=50, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=50, out_features=100, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=100, out_features=1216, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (unflatten): Unflatten(dim=1, unflattened_size=(32, 38))\n",
       "  (convnet): Sequential(\n",
       "    (0): ConvTranspose1d(32, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): ConvTranspose1d(16, 8, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): ConvTranspose1d(8, 1, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_decoder = ConvolutionalDecoder(latent_dims=10 + 5 + 1, signal_dims=300)\n",
    "current_decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_decoder.parameters().__next__().requires_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded = tensor([[0.0355, 0.1487, 0.0441, 0.1156, 0.0283, 0.1418, 0.0135, 0.1049, 0.0328,\n",
      "         0.1448, 0.0355, 0.1072, 0.0214, 0.1316, 0.0104, 0.1116, 0.0271, 0.1539,\n",
      "         0.0343, 0.1019, 0.0249, 0.1396, 0.0261, 0.1059, 0.0251, 0.1328, 0.0339,\n",
      "         0.1187, 0.0279, 0.1428, 0.0208, 0.1125, 0.0299, 0.1541, 0.0083, 0.0921,\n",
      "         0.0286, 0.1398, 0.0042, 0.1082, 0.0246, 0.1470, 0.0522, 0.1215, 0.0211,\n",
      "         0.1342, 0.0000, 0.1140, 0.0333, 0.1581, 0.0306, 0.1058, 0.0286, 0.1353,\n",
      "         0.0079, 0.1156, 0.0271, 0.1461, 0.0283, 0.1103, 0.0328, 0.1359, 0.0195,\n",
      "         0.1135, 0.0254, 0.1417, 0.0515, 0.1285, 0.0327, 0.1401, 0.0236, 0.1130,\n",
      "         0.0248, 0.1394, 0.0334, 0.1194, 0.0299, 0.1431, 0.0330, 0.1147, 0.0286,\n",
      "         0.1422, 0.0307, 0.1072, 0.0259, 0.1374, 0.0215, 0.1096, 0.0291, 0.1372,\n",
      "         0.0377, 0.1099, 0.0218, 0.1382, 0.0221, 0.1093, 0.0275, 0.1425, 0.0095,\n",
      "         0.0959, 0.0277, 0.1412, 0.0211, 0.1149, 0.0246, 0.1420, 0.0366, 0.1146,\n",
      "         0.0313, 0.1390, 0.0151, 0.1059, 0.0244, 0.1307, 0.0322, 0.1107, 0.0231,\n",
      "         0.1418, 0.0219, 0.1109, 0.0252, 0.1407, 0.0365, 0.1104, 0.0232, 0.1357,\n",
      "         0.0219, 0.1105, 0.0269, 0.1467, 0.0315, 0.1034, 0.0247, 0.1412, 0.0285,\n",
      "         0.1169, 0.0288, 0.1444, 0.0332, 0.1073, 0.0359, 0.1393, 0.0142, 0.1211,\n",
      "         0.0284, 0.1446, 0.0514, 0.1181, 0.0250, 0.1311, 0.0020, 0.1207, 0.0266,\n",
      "         0.1548, 0.0247, 0.0975, 0.0251, 0.1360, 0.0135, 0.1144, 0.0341, 0.1552,\n",
      "         0.0237, 0.1096, 0.0335, 0.1509, 0.0000, 0.0988, 0.0305, 0.1545, 0.0104,\n",
      "         0.1034, 0.0315, 0.1440, 0.0171, 0.1220, 0.0341, 0.1638, 0.0367, 0.1043,\n",
      "         0.0296, 0.1366, 0.0028, 0.1140, 0.0341, 0.1552, 0.0256, 0.0999, 0.0229,\n",
      "         0.1369, 0.0091, 0.1112, 0.0312, 0.1520, 0.0374, 0.0982, 0.0220, 0.1306,\n",
      "         0.0082, 0.1100, 0.0300, 0.1459, 0.0444, 0.1169, 0.0229, 0.1341, 0.0101,\n",
      "         0.1051, 0.0292, 0.1494, 0.0370, 0.1083, 0.0274, 0.1357, 0.0303, 0.1145,\n",
      "         0.0244, 0.1332, 0.0327, 0.1197, 0.0284, 0.1487, 0.0266, 0.1194, 0.0341,\n",
      "         0.1567, 0.0325, 0.1048, 0.0253, 0.1351, 0.0103, 0.1105, 0.0329, 0.1517,\n",
      "         0.0355, 0.1017, 0.0245, 0.1355, 0.0027, 0.1026, 0.0233, 0.1444, 0.0376,\n",
      "         0.1085, 0.0236, 0.1326, 0.0320, 0.1234, 0.0237, 0.1492, 0.0570, 0.1284,\n",
      "         0.0327, 0.1419, 0.0320, 0.1180, 0.0265, 0.1508, 0.0491, 0.1141, 0.0256,\n",
      "         0.1249, 0.0112, 0.1197, 0.0299, 0.1463, 0.0337, 0.1020, 0.0248, 0.1416,\n",
      "         0.0275, 0.1263, 0.0307, 0.1522, 0.0430, 0.1053, 0.0295, 0.1467, 0.0159,\n",
      "         0.1074, 0.0330, 0.1502, 0.0404, 0.1113, 0.0259, 0.1272, 0.0219, 0.1194,\n",
      "         0.0310, 0.1504, 0.0296, 0.1000, 0.0267, 0.1360, 0.0255, 0.1187, 0.0257,\n",
      "         0.1473, 0.0257, 0.0207],\n",
      "        [0.0307, 0.1472, 0.0508, 0.1216, 0.0282, 0.1402, 0.0198, 0.1070, 0.0328,\n",
      "         0.1434, 0.0318, 0.1050, 0.0223, 0.1317, 0.0115, 0.1089, 0.0278, 0.1494,\n",
      "         0.0267, 0.0999, 0.0237, 0.1405, 0.0285, 0.1106, 0.0264, 0.1386, 0.0445,\n",
      "         0.1159, 0.0252, 0.1375, 0.0200, 0.1100, 0.0287, 0.1512, 0.0067, 0.0928,\n",
      "         0.0291, 0.1389, 0.0012, 0.1107, 0.0269, 0.1451, 0.0386, 0.1172, 0.0231,\n",
      "         0.1370, 0.0000, 0.1084, 0.0305, 0.1532, 0.0346, 0.1140, 0.0321, 0.1430,\n",
      "         0.0099, 0.1174, 0.0290, 0.1465, 0.0218, 0.1083, 0.0326, 0.1408, 0.0231,\n",
      "         0.1099, 0.0265, 0.1414, 0.0499, 0.1240, 0.0288, 0.1379, 0.0250, 0.1082,\n",
      "         0.0237, 0.1365, 0.0308, 0.1162, 0.0282, 0.1411, 0.0281, 0.1198, 0.0299,\n",
      "         0.1480, 0.0427, 0.1070, 0.0233, 0.1314, 0.0182, 0.1110, 0.0288, 0.1378,\n",
      "         0.0408, 0.1101, 0.0219, 0.1388, 0.0282, 0.1105, 0.0263, 0.1387, 0.0180,\n",
      "         0.1013, 0.0290, 0.1425, 0.0262, 0.1161, 0.0245, 0.1401, 0.0451, 0.1245,\n",
      "         0.0311, 0.1383, 0.0233, 0.1090, 0.0242, 0.1297, 0.0325, 0.1103, 0.0232,\n",
      "         0.1393, 0.0191, 0.1105, 0.0274, 0.1442, 0.0267, 0.1028, 0.0230, 0.1356,\n",
      "         0.0169, 0.1113, 0.0275, 0.1525, 0.0334, 0.1005, 0.0235, 0.1398, 0.0293,\n",
      "         0.1172, 0.0275, 0.1443, 0.0343, 0.1053, 0.0343, 0.1386, 0.0157, 0.1204,\n",
      "         0.0269, 0.1398, 0.0438, 0.1136, 0.0243, 0.1340, 0.0101, 0.1185, 0.0244,\n",
      "         0.1509, 0.0347, 0.1052, 0.0257, 0.1387, 0.0109, 0.1109, 0.0347, 0.1597,\n",
      "         0.0276, 0.1048, 0.0323, 0.1467, 0.0000, 0.1003, 0.0309, 0.1509, 0.0148,\n",
      "         0.1059, 0.0302, 0.1426, 0.0136, 0.1221, 0.0370, 0.1668, 0.0310, 0.1019,\n",
      "         0.0281, 0.1388, 0.0063, 0.1156, 0.0339, 0.1576, 0.0277, 0.0963, 0.0220,\n",
      "         0.1320, 0.0039, 0.1121, 0.0281, 0.1486, 0.0411, 0.1008, 0.0219, 0.1311,\n",
      "         0.0091, 0.1084, 0.0281, 0.1444, 0.0426, 0.1152, 0.0238, 0.1341, 0.0122,\n",
      "         0.1072, 0.0313, 0.1497, 0.0372, 0.1078, 0.0264, 0.1338, 0.0266, 0.1140,\n",
      "         0.0252, 0.1359, 0.0351, 0.1182, 0.0287, 0.1443, 0.0234, 0.1191, 0.0329,\n",
      "         0.1530, 0.0305, 0.1070, 0.0267, 0.1357, 0.0095, 0.1105, 0.0347, 0.1533,\n",
      "         0.0349, 0.1004, 0.0233, 0.1330, 0.0071, 0.1052, 0.0237, 0.1445, 0.0428,\n",
      "         0.1103, 0.0240, 0.1324, 0.0308, 0.1239, 0.0239, 0.1483, 0.0574, 0.1270,\n",
      "         0.0324, 0.1466, 0.0322, 0.1126, 0.0235, 0.1535, 0.0594, 0.1225, 0.0271,\n",
      "         0.1213, 0.0110, 0.1213, 0.0316, 0.1467, 0.0323, 0.1020, 0.0255, 0.1388,\n",
      "         0.0208, 0.1227, 0.0309, 0.1549, 0.0396, 0.1056, 0.0303, 0.1448, 0.0129,\n",
      "         0.1114, 0.0331, 0.1524, 0.0387, 0.1109, 0.0273, 0.1275, 0.0183, 0.1198,\n",
      "         0.0329, 0.1554, 0.0249, 0.0961, 0.0254, 0.1426, 0.0332, 0.1184, 0.0253,\n",
      "         0.1467, 0.0264, 0.0206],\n",
      "        [0.0321, 0.1429, 0.0428, 0.1153, 0.0301, 0.1438, 0.0192, 0.1079, 0.0335,\n",
      "         0.1454, 0.0259, 0.1057, 0.0224, 0.1372, 0.0088, 0.1053, 0.0292, 0.1546,\n",
      "         0.0258, 0.0967, 0.0225, 0.1377, 0.0224, 0.1101, 0.0263, 0.1368, 0.0365,\n",
      "         0.1169, 0.0268, 0.1428, 0.0206, 0.1010, 0.0290, 0.1444, 0.0046, 0.0955,\n",
      "         0.0283, 0.1360, 0.0004, 0.1130, 0.0273, 0.1456, 0.0439, 0.1182, 0.0239,\n",
      "         0.1336, 0.0000, 0.1075, 0.0302, 0.1493, 0.0343, 0.1175, 0.0326, 0.1412,\n",
      "         0.0064, 0.1204, 0.0294, 0.1441, 0.0181, 0.1134, 0.0370, 0.1450, 0.0239,\n",
      "         0.1124, 0.0250, 0.1447, 0.0618, 0.1279, 0.0279, 0.1356, 0.0281, 0.1087,\n",
      "         0.0232, 0.1324, 0.0228, 0.1166, 0.0310, 0.1466, 0.0263, 0.1203, 0.0331,\n",
      "         0.1518, 0.0507, 0.1119, 0.0250, 0.1314, 0.0118, 0.1061, 0.0284, 0.1386,\n",
      "         0.0411, 0.1109, 0.0227, 0.1388, 0.0259, 0.1069, 0.0253, 0.1342, 0.0155,\n",
      "         0.1035, 0.0321, 0.1423, 0.0219, 0.1135, 0.0248, 0.1385, 0.0454, 0.1276,\n",
      "         0.0319, 0.1422, 0.0273, 0.1102, 0.0242, 0.1291, 0.0364, 0.1128, 0.0229,\n",
      "         0.1431, 0.0129, 0.1083, 0.0261, 0.1502, 0.0214, 0.0984, 0.0248, 0.1360,\n",
      "         0.0093, 0.1107, 0.0302, 0.1572, 0.0291, 0.0991, 0.0251, 0.1334, 0.0177,\n",
      "         0.1194, 0.0293, 0.1522, 0.0376, 0.0982, 0.0293, 0.1325, 0.0150, 0.1246,\n",
      "         0.0265, 0.1393, 0.0434, 0.1143, 0.0257, 0.1332, 0.0083, 0.1203, 0.0238,\n",
      "         0.1513, 0.0452, 0.1084, 0.0237, 0.1360, 0.0025, 0.1062, 0.0329, 0.1600,\n",
      "         0.0283, 0.1045, 0.0312, 0.1444, 0.0000, 0.1005, 0.0289, 0.1504, 0.0195,\n",
      "         0.1071, 0.0297, 0.1427, 0.0086, 0.1234, 0.0396, 0.1703, 0.0299, 0.0971,\n",
      "         0.0278, 0.1385, 0.0061, 0.1206, 0.0349, 0.1614, 0.0244, 0.0924, 0.0209,\n",
      "         0.1312, 0.0023, 0.1118, 0.0244, 0.1474, 0.0442, 0.1017, 0.0216, 0.1311,\n",
      "         0.0102, 0.1078, 0.0271, 0.1424, 0.0420, 0.1131, 0.0232, 0.1386, 0.0098,\n",
      "         0.1068, 0.0348, 0.1572, 0.0340, 0.1033, 0.0253, 0.1305, 0.0243, 0.1195,\n",
      "         0.0248, 0.1360, 0.0356, 0.1166, 0.0293, 0.1435, 0.0187, 0.1180, 0.0316,\n",
      "         0.1500, 0.0279, 0.1086, 0.0276, 0.1368, 0.0077, 0.1090, 0.0335, 0.1553,\n",
      "         0.0280, 0.0942, 0.0242, 0.1333, 0.0095, 0.1096, 0.0240, 0.1427, 0.0514,\n",
      "         0.1176, 0.0265, 0.1333, 0.0263, 0.1233, 0.0243, 0.1467, 0.0436, 0.1225,\n",
      "         0.0335, 0.1531, 0.0289, 0.1084, 0.0238, 0.1600, 0.0699, 0.1279, 0.0283,\n",
      "         0.1197, 0.0057, 0.1255, 0.0326, 0.1487, 0.0388, 0.1036, 0.0252, 0.1369,\n",
      "         0.0259, 0.1222, 0.0299, 0.1570, 0.0323, 0.1025, 0.0347, 0.1464, 0.0091,\n",
      "         0.1114, 0.0321, 0.1547, 0.0424, 0.1149, 0.0291, 0.1285, 0.0144, 0.1219,\n",
      "         0.0349, 0.1612, 0.0224, 0.0940, 0.0242, 0.1421, 0.0318, 0.1214, 0.0262,\n",
      "         0.1488, 0.0287, 0.0199]], grad_fn=<SqueezeBackward1>)\n",
      "decoded.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "latent = torch.rand(3, 10 + 5 + 1)\n",
    "decoded = current_decoder(latent)\n",
    "print(f\"{decoded = }\")\n",
    "print(f\"{decoded.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalDecoder(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=50, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=50, out_features=100, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=100, out_features=960, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (unflatten): Unflatten(dim=1, unflattened_size=(32, 30))\n",
       "  (convnet): Sequential(\n",
       "    (0): ConvTranspose1d(32, 16, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): ConvTranspose1d(16, 8, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): ConvTranspose1d(8, 1, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formfactor_decoder = ConvolutionalDecoder(latent_dims=10 + 5 + 1, signal_dims=240)\n",
    "formfactor_decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded = tensor([[0.3804, 0.1999, 0.2930, 0.2704, 0.3945, 0.2424, 0.3304, 0.2652, 0.3852,\n",
      "         0.2451, 0.3454, 0.2422, 0.3703, 0.1961, 0.3121, 0.2568, 0.3901, 0.2057,\n",
      "         0.3108, 0.2345, 0.3556, 0.2152, 0.3359, 0.2557, 0.3784, 0.2205, 0.3180,\n",
      "         0.2689, 0.3981, 0.2214, 0.3174, 0.2381, 0.3766, 0.2258, 0.3342, 0.2518,\n",
      "         0.3649, 0.2187, 0.3130, 0.2421, 0.3708, 0.2008, 0.3244, 0.2476, 0.3769,\n",
      "         0.2112, 0.3086, 0.2489, 0.3793, 0.2085, 0.3416, 0.2453, 0.3693, 0.2167,\n",
      "         0.2994, 0.2462, 0.3780, 0.2090, 0.2972, 0.2601, 0.3803, 0.2080, 0.3357,\n",
      "         0.2604, 0.3832, 0.2199, 0.3416, 0.2695, 0.3751, 0.2250, 0.3093, 0.2344,\n",
      "         0.3715, 0.2310, 0.3437, 0.2533, 0.3693, 0.2076, 0.2977, 0.2413, 0.3652,\n",
      "         0.1841, 0.3266, 0.2417, 0.3718, 0.2159, 0.3322, 0.2646, 0.3925, 0.2159,\n",
      "         0.3040, 0.2416, 0.3752, 0.1862, 0.3167, 0.2422, 0.3774, 0.2132, 0.3261,\n",
      "         0.2603, 0.3885, 0.2311, 0.3176, 0.2304, 0.3747, 0.1726, 0.3208, 0.2621,\n",
      "         0.3688, 0.2487, 0.3455, 0.2478, 0.3861, 0.2001, 0.3343, 0.2436, 0.3719,\n",
      "         0.2220, 0.3150, 0.2379, 0.3768, 0.1948, 0.3262, 0.2529, 0.3661, 0.2295,\n",
      "         0.3437, 0.2383, 0.3844, 0.2192, 0.3104, 0.2376, 0.3671, 0.2309, 0.3500,\n",
      "         0.2507, 0.3717, 0.2076, 0.3023, 0.2653, 0.4105, 0.2267, 0.3327, 0.2423,\n",
      "         0.3839, 0.2242, 0.3413, 0.2426, 0.3865, 0.2263, 0.3242, 0.2459, 0.3687,\n",
      "         0.2114, 0.3410, 0.2608, 0.3947, 0.2088, 0.3131, 0.2573, 0.3740, 0.2064,\n",
      "         0.3433, 0.2341, 0.3537, 0.2114, 0.3238, 0.2548, 0.3738, 0.2154, 0.3408,\n",
      "         0.2417, 0.3493, 0.2120, 0.3226, 0.2406, 0.3709, 0.1890, 0.3136, 0.2064,\n",
      "         0.3434, 0.1797, 0.3202, 0.2543, 0.3805, 0.1973, 0.3179, 0.2430, 0.3657,\n",
      "         0.2146, 0.2975, 0.2372, 0.3838, 0.2013, 0.3270, 0.2397, 0.3829, 0.2268,\n",
      "         0.3466, 0.2448, 0.3755, 0.2045, 0.3373, 0.2554, 0.3630, 0.2267, 0.3146,\n",
      "         0.2598, 0.3849, 0.2104, 0.3231, 0.2669, 0.3858, 0.2159, 0.3205, 0.2451,\n",
      "         0.3912, 0.2120, 0.3138, 0.2698, 0.3947, 0.2283, 0.3292, 0.2379, 0.3673,\n",
      "         0.2112, 0.3220, 0.2574, 0.3745, 0.2138, 0.3211, 0.2508, 0.3818, 0.2006,\n",
      "         0.2999, 0.2101, 0.3665, 0.2231, 0.3460, 0.1004],\n",
      "        [0.3773, 0.1994, 0.3007, 0.2636, 0.3878, 0.2292, 0.3330, 0.2594, 0.3820,\n",
      "         0.2299, 0.3347, 0.2482, 0.3606, 0.1981, 0.3145, 0.2565, 0.3878, 0.2087,\n",
      "         0.3171, 0.2435, 0.3584, 0.2191, 0.3330, 0.2531, 0.3740, 0.2133, 0.3212,\n",
      "         0.2671, 0.3944, 0.2113, 0.3137, 0.2290, 0.3735, 0.2160, 0.3294, 0.2606,\n",
      "         0.3714, 0.2212, 0.3169, 0.2482, 0.3756, 0.2110, 0.3292, 0.2512, 0.3744,\n",
      "         0.2173, 0.3107, 0.2419, 0.3792, 0.2040, 0.3310, 0.2255, 0.3592, 0.2062,\n",
      "         0.3092, 0.2498, 0.3791, 0.2057, 0.2901, 0.2544, 0.3787, 0.1971, 0.3276,\n",
      "         0.2664, 0.3828, 0.2230, 0.3346, 0.2805, 0.3873, 0.2406, 0.3146, 0.2383,\n",
      "         0.3752, 0.2256, 0.3340, 0.2572, 0.3635, 0.2007, 0.2941, 0.2511, 0.3717,\n",
      "         0.2038, 0.3291, 0.2410, 0.3755, 0.2186, 0.3312, 0.2638, 0.3889, 0.2100,\n",
      "         0.3104, 0.2432, 0.3822, 0.1944, 0.3278, 0.2475, 0.3795, 0.2146, 0.3261,\n",
      "         0.2575, 0.3867, 0.2281, 0.3253, 0.2340, 0.3748, 0.1785, 0.3215, 0.2591,\n",
      "         0.3633, 0.2321, 0.3369, 0.2513, 0.3876, 0.2102, 0.3273, 0.2384, 0.3691,\n",
      "         0.2185, 0.3180, 0.2445, 0.3779, 0.1969, 0.3226, 0.2555, 0.3654, 0.2242,\n",
      "         0.3415, 0.2393, 0.3802, 0.2169, 0.3120, 0.2460, 0.3748, 0.2348, 0.3480,\n",
      "         0.2551, 0.3750, 0.2103, 0.3039, 0.2595, 0.3982, 0.2224, 0.3348, 0.2481,\n",
      "         0.3813, 0.2282, 0.3460, 0.2467, 0.3872, 0.2310, 0.3260, 0.2424, 0.3675,\n",
      "         0.2032, 0.3296, 0.2651, 0.3915, 0.2124, 0.3157, 0.2614, 0.3750, 0.2129,\n",
      "         0.3528, 0.2340, 0.3577, 0.2177, 0.3246, 0.2538, 0.3772, 0.2171, 0.3373,\n",
      "         0.2491, 0.3535, 0.2177, 0.3293, 0.2396, 0.3693, 0.1875, 0.3164, 0.2044,\n",
      "         0.3460, 0.1782, 0.3213, 0.2539, 0.3807, 0.1947, 0.3125, 0.2375, 0.3585,\n",
      "         0.2059, 0.3075, 0.2420, 0.3824, 0.2019, 0.3198, 0.2415, 0.3916, 0.2270,\n",
      "         0.3476, 0.2434, 0.3739, 0.2072, 0.3400, 0.2468, 0.3565, 0.2177, 0.3070,\n",
      "         0.2631, 0.3799, 0.2112, 0.3305, 0.2522, 0.3826, 0.2093, 0.3119, 0.2438,\n",
      "         0.3893, 0.2079, 0.3128, 0.2725, 0.3958, 0.2272, 0.3364, 0.2400, 0.3693,\n",
      "         0.2148, 0.3236, 0.2581, 0.3759, 0.2147, 0.3286, 0.2494, 0.3776, 0.2016,\n",
      "         0.3080, 0.2171, 0.3645, 0.2248, 0.3486, 0.1029],\n",
      "        [0.3852, 0.2072, 0.2927, 0.2772, 0.4062, 0.2501, 0.3349, 0.2667, 0.3842,\n",
      "         0.2461, 0.3445, 0.2461, 0.3706, 0.1970, 0.3101, 0.2604, 0.3943, 0.2079,\n",
      "         0.3136, 0.2241, 0.3414, 0.2089, 0.3354, 0.2568, 0.3783, 0.2147, 0.3093,\n",
      "         0.2606, 0.3975, 0.2097, 0.3197, 0.2320, 0.3749, 0.2241, 0.3210, 0.2445,\n",
      "         0.3673, 0.2123, 0.3141, 0.2421, 0.3758, 0.1913, 0.3073, 0.2480, 0.3673,\n",
      "         0.2110, 0.3164, 0.2452, 0.3823, 0.2097, 0.3333, 0.2474, 0.3725, 0.2236,\n",
      "         0.3082, 0.2419, 0.3836, 0.1932, 0.2891, 0.2429, 0.3729, 0.2091, 0.3501,\n",
      "         0.2625, 0.3798, 0.2116, 0.3422, 0.2796, 0.3739, 0.2295, 0.3044, 0.2370,\n",
      "         0.3750, 0.2410, 0.3519, 0.2494, 0.3629, 0.2084, 0.3033, 0.2356, 0.3645,\n",
      "         0.1783, 0.3210, 0.2375, 0.3695, 0.2157, 0.3269, 0.2714, 0.3953, 0.2278,\n",
      "         0.3127, 0.2481, 0.3785, 0.1895, 0.3232, 0.2526, 0.3847, 0.2174, 0.3275,\n",
      "         0.2551, 0.3783, 0.2243, 0.3156, 0.2315, 0.3759, 0.1596, 0.3143, 0.2677,\n",
      "         0.3649, 0.2479, 0.3545, 0.2494, 0.3881, 0.2057, 0.3320, 0.2469, 0.3742,\n",
      "         0.2233, 0.3256, 0.2392, 0.3760, 0.2004, 0.3324, 0.2793, 0.3770, 0.2485,\n",
      "         0.3443, 0.2312, 0.3919, 0.2111, 0.3047, 0.2378, 0.3722, 0.2400, 0.3607,\n",
      "         0.2535, 0.3732, 0.2130, 0.3175, 0.2665, 0.4156, 0.2338, 0.3406, 0.2379,\n",
      "         0.3807, 0.2185, 0.3405, 0.2360, 0.3836, 0.2244, 0.3226, 0.2452, 0.3701,\n",
      "         0.2038, 0.3324, 0.2578, 0.3909, 0.2032, 0.3092, 0.2596, 0.3746, 0.2114,\n",
      "         0.3525, 0.2459, 0.3556, 0.2241, 0.3258, 0.2596, 0.3742, 0.2105, 0.3445,\n",
      "         0.2325, 0.3443, 0.1939, 0.3191, 0.2303, 0.3665, 0.1747, 0.3023, 0.2163,\n",
      "         0.3459, 0.1854, 0.3300, 0.2619, 0.3822, 0.1978, 0.3181, 0.2454, 0.3601,\n",
      "         0.2112, 0.2951, 0.2329, 0.3786, 0.1907, 0.3114, 0.2393, 0.3804, 0.2222,\n",
      "         0.3480, 0.2359, 0.3785, 0.2015, 0.3308, 0.2643, 0.3669, 0.2380, 0.3170,\n",
      "         0.2677, 0.3921, 0.2137, 0.3170, 0.2706, 0.3927, 0.2197, 0.3267, 0.2490,\n",
      "         0.3966, 0.2235, 0.3031, 0.2546, 0.3998, 0.2233, 0.3358, 0.2379, 0.3695,\n",
      "         0.2188, 0.3300, 0.2458, 0.3671, 0.2016, 0.3237, 0.2520, 0.3757, 0.1948,\n",
      "         0.2945, 0.2145, 0.3636, 0.2241, 0.3486, 0.0999]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "decoded.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "latent = torch.rand(3, 10 + 5 + 1)\n",
    "decoded = formfactor_decoder(latent)\n",
    "print(f\"{decoded = }\")\n",
    "print(f\"{decoded.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (formfactor_encoder): ConvolutionalEncoder(\n",
       "    (convnet): Sequential(\n",
       "      (0): Conv1d(1, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=960, out_features=100, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (current_decoder): ConvolutionalDecoder(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=50, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=50, out_features=100, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=100, out_features=1216, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (unflatten): Unflatten(dim=1, unflattened_size=(32, 38))\n",
       "    (convnet): Sequential(\n",
       "      (0): ConvTranspose1d(32, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): ConvTranspose1d(16, 8, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): ConvTranspose1d(8, 1, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "      (5): ReLU()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = Generator()\n",
    "generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.parameters().__next__().requires_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_profile.size() = torch.Size([3, 300])\n",
      "current_profile.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "formfactor = torch.rand(3, 240)\n",
    "rf_settings = torch.rand(3, 5)\n",
    "bunch_length = torch.rand(3, 1)\n",
    "\n",
    "current_profile = generator(formfactor, rf_settings, bunch_length)\n",
    "print(f\"{current_profile.size() = }\")\n",
    "print(f\"{current_profile.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Critic(\n",
       "  (formfactor_encoder): ConvolutionalEncoder(\n",
       "    (convnet): Sequential(\n",
       "      (0): Conv1d(1, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=960, out_features=100, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (current_encoder): ConvolutionalEncoder(\n",
       "    (convnet): Sequential(\n",
       "      (0): Conv1d(1, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=1216, out_features=100, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=26, out_features=50, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=50, out_features=20, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=20, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic = Critic()\n",
    "critic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "critique = tensor([[-0.0183],\n",
      "        [ 0.0024],\n",
      "        [-0.0005]], grad_fn=<AddmmBackward0>)\n",
      "critique.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "critique = critic(current_profile, formfactor, rf_settings, bunch_length)\n",
    "print(f\"{critique = }\")\n",
    "print(f\"{critique.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<train_gan.EuXFELCurrentDataset at 0x296c970d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = EuXFELCurrentDataset()\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "(formfactor, rf_settings, bunch_length), current_profile = dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.1136,  0.9786,  1.0596,  0.9905,  0.9889,  0.8491,  0.9743,  0.9680,\n",
       "         0.9987,  0.9678,  0.9987,  0.8583,  0.9538,  0.9625,  0.9760,  1.1724,\n",
       "         0.9697,  0.9435,  0.9241,  0.9130,  0.9376,  0.9233,  0.8949,  0.8922,\n",
       "         0.9359,  0.9103,  0.9332,  0.9133,  0.8929,  0.9105,  0.8257,  0.8823,\n",
       "         0.8891,  0.8212,  0.8671,  0.8750,  0.8668,  0.8590,  0.8542,  0.8362,\n",
       "         0.8528,  0.8493,  0.8486,  0.8386,  0.8386,  0.8227,  0.8215,  0.8296,\n",
       "         0.8120,  0.8044,  0.7988,  0.7836,  0.7764,  0.7696,  0.7519,  0.7426,\n",
       "         0.7177,  0.6808,  0.6909,  0.6645,  0.6718,  0.5611,  0.6621,  0.5888,\n",
       "         0.6114,  0.6397,  0.6155,  0.6192,  0.5929,  0.6077,  0.5308,  0.5788,\n",
       "         0.5683,  0.5319,  0.5339,  0.5141,  0.5032,  0.4987,  0.4759,  0.4483,\n",
       "         0.4318,  0.4187,  0.3994,  0.3706,  0.3445,  0.3279,  0.3064,  0.2693,\n",
       "         0.2370,  0.2587, -0.2030,  0.2165,  0.3358,  0.1943,  0.3144,  0.1282,\n",
       "         0.1266,  0.1986,  0.1814,  0.1547,  0.1980,  0.1202,  0.1434,  0.1359,\n",
       "         0.1554,  0.1316,  0.1473,  0.1035,  0.1683,  0.1528,  0.1455,  0.1674,\n",
       "         0.1680,  0.1845,  0.1746,  0.1895,  0.1873,  0.1920,  0.1805,  0.1755,\n",
       "         0.0857,  0.1585,  0.0312,  0.1787,  0.1666,  0.1703,  0.1261,  0.1328,\n",
       "         0.1604,  0.1491,  0.1249,  0.0978,  0.1264,  0.1063,  0.1026, -0.2541,\n",
       "         0.0894,  0.0723,  0.0748,  0.0968,  0.0917,  0.0953,  0.1051,  0.1136,\n",
       "         0.1191,  0.1209,  0.1202,  0.1140,  0.0932,  0.0637,  0.0985,  0.0893,\n",
       "         0.0563,  0.0927, -0.1443,  0.0727,  0.0661,  0.0799,  0.0730,  0.0453,\n",
       "         0.0578, -0.0329,  0.0670,  0.1029,  0.0490,  0.0850,  0.0623,  0.1070,\n",
       "         0.0897,  0.0929,  0.0910,  0.0834,  0.0781,  0.0548,  0.0484,  0.0381,\n",
       "         0.0456,  0.0565,  0.0654,  0.0592,  0.0125,  0.0877,  0.0398,  0.0229,\n",
       "        -0.0126,  0.0424, -0.0414, -0.0679,  0.0290,  0.0636,  0.0529,  0.0468,\n",
       "         0.0550,  0.0487,  0.0471,  0.0444,  0.0304,  0.0223,  0.0080,  0.0346,\n",
       "         0.0402,  0.0368,  0.0435,  0.0238,  0.0144,  0.0247,  0.0379,  0.0204,\n",
       "         0.0091,  0.0989, -0.0325,  0.0196, -0.0346,  0.0295,  0.0652,  0.0484,\n",
       "        -0.0334,  0.0138,  0.0237,  0.0288,  0.0180,  0.0297,  0.0232,  0.0099,\n",
       "         0.0214,  0.0293,  0.0274,  0.0422,  0.0098,  0.0162, -0.0705,  0.0164,\n",
       "        -0.0241, -0.0140, -0.0229, -0.0198,  0.0078,  0.0215,  0.0690, -0.0840])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formfactor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-7.4400e+00,  2.8130e+02,  4.5442e+04, -1.3430e+01,  2.1100e+00])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.0783e-05])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bunch_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 179.1833,  265.1158,  370.1751,  491.9395,  626.4266,  768.1013,\n",
       "         908.7740, 1042.1052, 1162.9528, 1264.8722, 1348.4093, 1413.8678,\n",
       "        1462.4076, 1493.7413, 1512.1744, 1519.9905, 1519.4473, 1512.3607,\n",
       "        1502.1366, 1490.9547, 1480.4468, 1471.3280, 1463.6165, 1456.7324,\n",
       "        1449.9124, 1442.8661, 1435.5945, 1428.8264, 1423.0869, 1419.1271,\n",
       "        1416.9052, 1415.7997, 1415.0654, 1413.8822, 1411.8910, 1409.0577,\n",
       "        1405.5623, 1401.7904, 1397.8761, 1393.8970, 1390.1157, 1387.0282,\n",
       "        1384.8540, 1383.8727, 1383.8990, 1384.2417, 1383.5660, 1380.6753,\n",
       "        1374.9377, 1366.2657, 1356.0144, 1346.1371, 1338.5245, 1334.9456,\n",
       "        1335.8098, 1340.0797, 1346.2191, 1352.3209, 1356.5610, 1357.8591,\n",
       "        1355.5807, 1349.4393, 1340.0415, 1328.5688, 1316.5232, 1305.4174,\n",
       "        1296.7922, 1291.0576, 1288.1896, 1287.8152, 1289.4836, 1292.4856,\n",
       "        1296.4257, 1300.7830, 1304.6067, 1307.0728, 1307.5531, 1305.6469,\n",
       "        1301.3713, 1295.5537, 1288.7943, 1281.6586, 1274.7197, 1268.8696,\n",
       "        1264.6313, 1262.5005, 1262.1154, 1262.1019, 1260.9780, 1257.2867,\n",
       "        1249.9773, 1240.0989, 1229.0289, 1218.6681, 1211.3458, 1207.7805,\n",
       "        1208.2054, 1211.8888, 1217.3285, 1221.9727, 1224.0422, 1222.2666,\n",
       "        1215.5594, 1205.0040, 1191.6608, 1176.6780, 1161.4698, 1147.1185,\n",
       "        1134.6243, 1124.8486, 1118.9165, 1116.4080, 1116.8114, 1119.0972,\n",
       "        1122.1719, 1125.0762, 1127.3248, 1128.8667, 1129.5229, 1129.1501,\n",
       "        1127.1558, 1122.9415, 1115.7234, 1106.2776, 1095.7361, 1085.6208,\n",
       "        1078.0215, 1074.0427, 1073.8761, 1076.9758, 1082.3121, 1088.0555,\n",
       "        1092.9122, 1096.0947, 1096.9550, 1095.6292, 1092.6721, 1088.3611,\n",
       "        1082.8762, 1076.2614, 1068.3983, 1059.0015, 1047.6423, 1034.3521,\n",
       "        1019.6658, 1004.2232,  989.0231,  975.2514,  963.6213,  954.6097,\n",
       "         948.3491,  944.3639,  941.6473,  939.3870,  936.7869,  933.2231,\n",
       "         928.5677,  922.8477,  916.1462,  908.6627,  900.9128,  893.1390,\n",
       "         885.6578,  878.5041,  871.5567,  864.5103,  856.9824,  848.5487,\n",
       "         839.1793,  828.8627,  817.7148,  805.8785,  793.7277,  781.6601,\n",
       "         770.1476,  759.9048,  751.2829,  744.6625,  740.2706,  738.4003,\n",
       "         738.3168,  739.6046,  741.6005,  743.5164,  744.5435,  744.0992,\n",
       "         741.6838,  736.8547,  729.8548,  720.9260,  710.4181,  698.9488,\n",
       "         687.4023,  676.4956,  666.9177,  659.2346,  653.3217,  649.0088,\n",
       "         645.9459,  643.7675,  641.9937,  640.2684,  638.2169,  635.5790,\n",
       "         632.2490,  628.2607,  623.6092,  618.4365,  612.9874,  607.4666,\n",
       "         602.0009,  596.7210,  591.7306,  587.1321,  582.8207,  579.0054,\n",
       "         575.5805,  572.5874,  570.0806,  568.2402,  567.1962,  567.1440,\n",
       "         568.3934,  571.3211,  576.2237,  583.0677,  591.7641,  601.7861,\n",
       "         611.9141,  620.5814,  625.8419,  624.6522,  614.5303,  593.7863,\n",
       "         561.1049,  514.9560,  457.5943,  392.8271,  324.7126,  258.2587,\n",
       "         198.0663,  146.5870,  105.0448,   74.1945,   52.3957,   37.3627,\n",
       "          27.4340,   21.3620,   17.7514,   15.5304,   14.1450,   13.1850,\n",
       "          12.4636,   11.8231,   11.2314,   10.6607,   10.1095,    9.5635,\n",
       "           9.0194,    8.4614,    7.8842,    7.2767,    6.6262,    5.9659,\n",
       "           5.3574,    4.8523,    4.4884,    4.3060,    4.2625,    4.2711,\n",
       "           4.2769,    4.2555,    4.1793,    4.0757,    3.9685,    3.8736,\n",
       "           3.7917,    3.7116,    3.6248,    3.5051,    3.3435,    3.1277,\n",
       "           2.8783,    2.6425,    2.4862,    2.4393,    2.5071,    2.6408,\n",
       "           2.7782,    2.8578,    2.8474,    2.7545,    2.6347,    2.5309,\n",
       "           2.4717,    2.4547,    2.4519,    2.4130,    2.2959,    2.0813])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<train_gan.EuXFELCurrentDataModule at 0x296c97580>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module = EuXFELCurrentDataModule(batch_size=64)\n",
    "data_module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.setup(stage=\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x296c97670>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = data_module.train_dataloader()\n",
    "data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spectral-vd-euxfel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
