{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from train_gan import (\n",
    "    Critic,\n",
    "    EuXFELCurrentDataModule,\n",
    "    EuXFELCurrentDataset,\n",
    "    Generator,\n",
    "    ConvolutionalDecoder,\n",
    "    ConvolutionalEncoder,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalEncoder(\n",
       "  (convnet): Sequential(\n",
       "    (0): Conv1d(1, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=960, out_features=100, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formfactor_encoder = ConvolutionalEncoder(signal_dims=240, latent_dims=10)\n",
    "formfactor_encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded = tensor([[-0.1044, -0.1262, -0.0411, -0.0960, -0.0570, -0.1411,  0.0819,  0.0235,\n",
      "         -0.0648, -0.0935],\n",
      "        [-0.1040, -0.1261, -0.0408, -0.0961, -0.0574, -0.1407,  0.0816,  0.0229,\n",
      "         -0.0650, -0.0933],\n",
      "        [-0.1048, -0.1260, -0.0408, -0.0958, -0.0573, -0.1414,  0.0820,  0.0226,\n",
      "         -0.0650, -0.0936]], grad_fn=<AddmmBackward0>)\n",
      "encoded.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "formfactor = torch.rand(3, 240)\n",
    "encoded = formfactor_encoder(formfactor)\n",
    "print(f\"{encoded = }\")\n",
    "print(f\"{encoded.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalEncoder(\n",
       "  (convnet): Sequential(\n",
       "    (0): Conv1d(1, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=1216, out_features=100, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_encoder = ConvolutionalEncoder(signal_dims=300, latent_dims=10)\n",
    "current_encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded = tensor([[ 0.0040, -0.0270, -0.0408, -0.1242,  0.0279, -0.1028, -0.1106,  0.1344,\n",
      "         -0.0174, -0.0546],\n",
      "        [ 0.0033, -0.0286, -0.0406, -0.1248,  0.0279, -0.1040, -0.1130,  0.1342,\n",
      "         -0.0175, -0.0550],\n",
      "        [ 0.0033, -0.0276, -0.0395, -0.1246,  0.0304, -0.1035, -0.1098,  0.1344,\n",
      "         -0.0161, -0.0537]], grad_fn=<AddmmBackward0>)\n",
      "encoded.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "current_profile = torch.rand(3, 300)\n",
    "encoded = current_encoder(current_profile)\n",
    "print(f\"{encoded = }\")\n",
    "print(f\"{encoded.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalDecoder(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=50, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=50, out_features=100, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=100, out_features=1216, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (unflatten): Unflatten(dim=1, unflattened_size=(32, 38))\n",
       "  (convnet): Sequential(\n",
       "    (0): ConvTranspose1d(32, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): ConvTranspose1d(16, 8, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): ConvTranspose1d(8, 1, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_decoder = ConvolutionalDecoder(latent_dims=10 + 5 + 1, signal_dims=300)\n",
    "current_decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_decoder.parameters().__next__().requires_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded = tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "decoded.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "latent = torch.rand(3, 10 + 5 + 1)\n",
    "decoded = current_decoder(latent)\n",
    "print(f\"{decoded = }\")\n",
    "print(f\"{decoded.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalDecoder(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=50, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=50, out_features=100, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=100, out_features=960, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (unflatten): Unflatten(dim=1, unflattened_size=(32, 30))\n",
       "  (convnet): Sequential(\n",
       "    (0): ConvTranspose1d(32, 16, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): ConvTranspose1d(16, 8, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): ConvTranspose1d(8, 1, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formfactor_decoder = ConvolutionalDecoder(latent_dims=10 + 5 + 1, signal_dims=240)\n",
    "formfactor_decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded = tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "decoded.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "latent = torch.rand(3, 10 + 5 + 1)\n",
    "decoded = formfactor_decoder(latent)\n",
    "print(f\"{decoded = }\")\n",
    "print(f\"{decoded.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (formfactor_encoder): ConvolutionalEncoder(\n",
       "    (convnet): Sequential(\n",
       "      (0): Conv1d(1, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=960, out_features=100, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (scalar_spectral_combine_mlp): Sequential(\n",
       "    (0): Linear(in_features=15, out_features=50, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=50, out_features=20, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=20, out_features=10, bias=True)\n",
       "  )\n",
       "  (current_decoder): ConvolutionalDecoder(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=50, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=50, out_features=100, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=100, out_features=1216, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (unflatten): Unflatten(dim=1, unflattened_size=(32, 38))\n",
       "    (convnet): Sequential(\n",
       "      (0): ConvTranspose1d(32, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): ConvTranspose1d(16, 8, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): ConvTranspose1d(8, 1, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "      (5): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (bunch_length_decoder): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=20, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=20, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = Generator()\n",
    "generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.parameters().__next__().requires_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_profile.size() = torch.Size([3, 300])\n",
      "current_profile.requires_grad = True\n",
      "bunch_length.size() = torch.Size([3, 1])\n",
      "bunch_length.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "rf_settings = torch.rand(3, 5)\n",
    "formfactor = torch.rand(3, 240)\n",
    "\n",
    "current_profile, bunch_length = generator(rf_settings, formfactor)\n",
    "print(f\"{current_profile.size() = }\")\n",
    "print(f\"{current_profile.requires_grad = }\")\n",
    "print(f\"{bunch_length.size() = }\")\n",
    "print(f\"{bunch_length.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Critic(\n",
       "  (formfactor_encoder): ConvolutionalEncoder(\n",
       "    (convnet): Sequential(\n",
       "      (0): Conv1d(1, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=960, out_features=100, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (current_encoder): ConvolutionalEncoder(\n",
       "    (convnet): Sequential(\n",
       "      (0): Conv1d(1, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=1216, out_features=100, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=26, out_features=50, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=50, out_features=20, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=20, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic = Critic()\n",
    "critic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "critique = tensor([[-0.1880],\n",
      "        [-0.1769],\n",
      "        [-0.1727]], grad_fn=<AddmmBackward0>)\n",
      "critique.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "critique = critic(rf_settings, formfactor, current_profile, bunch_length)\n",
    "print(f\"{critique = }\")\n",
    "print(f\"{critique.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<train_gan.EuXFELCurrentDataset at 0x28fd138e0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = EuXFELCurrentDataset(normalize=True)\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25600"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(rf_settings, formfactor), (current_profile, bunch_length) = dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1088,  0.8982,  0.7778, -0.3842,  0.3934,  1.1806,  0.3513,  0.5333,\n",
       "         0.4273,  0.4169,  0.9124,  0.5842,  0.5516,  0.8963,  0.8173, -0.0905,\n",
       "         0.8763,  0.7232,  0.8295,  0.7835,  0.7825,  0.8283,  0.8010,  0.8343,\n",
       "         0.7814,  0.8849,  0.8978,  0.8681,  0.8983,  0.9119,  0.9508,  0.6962,\n",
       "         0.9910,  0.9971,  0.8135,  1.0166,  0.8453,  1.0088,  0.9617,  1.0021,\n",
       "         1.0230,  0.9885,  1.0004,  1.0561,  1.0639,  1.0924,  1.0754,  1.0793,\n",
       "         1.0991,  1.0668,  1.1638,  1.1874,  1.1758,  1.2214,  1.2338,  1.2624,\n",
       "         1.3026,  1.2957,  1.3394,  1.3627,  1.1388,  1.2419,  1.4109,  1.3788,\n",
       "         1.3503,  1.4213,  1.3817,  1.3550,  1.4236,  1.4270,  1.4571,  1.5076,\n",
       "         1.4982,  1.5231,  1.5010,  1.5507,  1.5560,  1.5790,  1.5979,  1.6012,\n",
       "         1.6426,  1.6666,  1.6868,  1.7104,  1.7388,  1.7728,  1.7886,  1.8227,\n",
       "         1.8537,  1.8489,  1.6903,  1.8300,  1.8327,  1.8037,  1.8014,  1.8423,\n",
       "         1.8530,  1.8607,  1.9009,  1.8958,  1.9167,  1.9405,  1.9474,  1.9533,\n",
       "         1.9803,  2.0034,  2.0080,  2.0215,  2.0646,  2.0750,  2.0839,  2.1104,\n",
       "         2.1358,  2.1601,  2.1752,  2.1945,  2.2156,  2.2283,  2.2530,  2.2504,\n",
       "         2.0658,  2.2005,  2.1986,  2.2465,  2.2290,  2.2486,  2.2564,  2.2778,\n",
       "         2.2537,  2.2731,  2.2731,  2.2807,  2.2938,  2.2949,  2.3039,  2.0095,\n",
       "         2.3030,  2.3038,  2.2994,  2.2977,  2.2893,  2.2824,  2.2659,  2.2471,\n",
       "         2.2232,  2.1972,  2.1651,  2.1140,  2.0618,  1.9708,  1.9745,  1.9630,\n",
       "         1.9902,  1.9870,  1.8718,  1.9748,  1.9461,  1.8954,  1.9094,  1.8886,\n",
       "         1.8749,  1.8364,  1.7981,  1.7540,  1.7358,  1.6905,  1.6225,  1.5413,\n",
       "         1.5094,  1.4348,  1.3559,  1.2610,  1.1595,  1.0393,  0.9086,  0.7733,\n",
       "         0.5958,  0.4280,  0.2090,  0.1094,  0.0801,  0.1810, -0.0243, -0.0142,\n",
       "        -0.0327, -0.1653, -0.2074, -0.1716,  0.0250,  0.2854,  0.1841,  0.3070,\n",
       "         0.3657,  0.4508,  0.5840,  0.6935,  0.8157,  0.9877,  1.1377,  1.2870,\n",
       "         1.4402,  1.6111,  1.7857,  1.9389,  2.0563,  2.1669,  2.2497,  2.2713,\n",
       "         2.2480,  0.5728,  1.6639,  1.9490,  2.0744,  1.9162,  1.8201,  1.9567,\n",
       "         1.8661,  1.9667,  1.8725,  1.7886,  1.6942,  1.5947,  1.4733,  1.2605,\n",
       "         0.9794,  0.8668,  0.4935, -0.0882,  0.2177, -0.9939,  0.7842,  0.6587,\n",
       "         0.8432,  1.2149,  1.5288,  2.3707,  2.5992,  2.4647,  1.7852, -0.7725])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formfactor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3616,  1.7155, -1.3814, -0.2878, -0.9114])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0020])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bunch_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4532, -0.4376, -0.4221, -0.4059, -0.3925, -0.3846, -0.3829, -0.3856,\n",
       "        -0.3896, -0.3934, -0.3964, -0.3985, -0.3999, -0.4005, -0.4007, -0.4005,\n",
       "        -0.4002, -0.4000, -0.3998, -0.3997, -0.3998, -0.4000, -0.4004, -0.4008,\n",
       "        -0.4013, -0.4015, -0.4019, -0.4037, -0.4074, -0.4126, -0.4183, -0.4243,\n",
       "        -0.4309, -0.4379, -0.4454, -0.4532, -0.4611, -0.4690, -0.4769, -0.4847,\n",
       "        -0.4922, -0.4992, -0.5053, -0.5109, -0.5174, -0.5251, -0.5326, -0.5390,\n",
       "        -0.5442, -0.5495, -0.5561, -0.5640, -0.5720, -0.5795, -0.5863, -0.5925,\n",
       "        -0.5986, -0.6056, -0.6132, -0.6202, -0.6254, -0.6270, -0.6191, -0.5927,\n",
       "        -0.5399, -0.4538, -0.3326, -0.1847, -0.0210,  0.1518,  0.3331,  0.5266,\n",
       "         0.7321,  0.9510,  1.1886,  1.4529,  1.7598,  2.1348,  2.5822,  3.0652,\n",
       "         3.4982,  3.7927,  3.9313,  3.9726,  4.0022,  4.0659,  4.1547,  4.2426,\n",
       "         4.3249,  4.3937,  4.4215,  4.3959,  4.3457,  4.2917,  4.2158,  4.0946,\n",
       "         3.9514,  3.8225,  3.7079,  3.5867,  3.4532,  3.3099,  3.1694,  3.0557,\n",
       "         2.9746,  2.9051,  2.8194,  2.7018,  2.5561,  2.4017,  2.2581,  2.1447,\n",
       "         2.0801,  2.0720,  2.1067,  2.1486,  2.1505,  2.0881,  1.9713,  1.8359,\n",
       "         1.7282,  1.6745,  1.6778,  1.7232,  1.7774,  1.8069,  1.8024,  1.7797,\n",
       "         1.7557,  1.7236,  1.6751,  1.6241,  1.5815,  1.5364,  1.4884,  1.4679,\n",
       "         1.4965,  1.5676,  1.6521,  1.7100,  1.7249,  1.7177,  1.7107,  1.6953,\n",
       "         1.6597,  1.6152,  1.5786,  1.5575,  1.5610,  1.6003,  1.6648,  1.7279,\n",
       "         1.7637,  1.7662,  1.7495,  1.7463,  1.7902,  1.8794,  1.9721,  2.0216,\n",
       "         2.0128,  1.9533,  1.8551,  1.7426,  1.6368,  1.5421,  1.4674,  1.4188,\n",
       "         1.3756,  1.3139,  1.2306,  1.1324,  1.0083,  0.8366,  0.6071,  0.3368,\n",
       "         0.0548, -0.2003, -0.3942, -0.5172, -0.5870, -0.6258, -0.6435, -0.6424,\n",
       "        -0.6362, -0.6426, -0.6649, -0.6914, -0.7074, -0.7141, -0.7232, -0.7362,\n",
       "        -0.7420, -0.7369, -0.7243, -0.7088, -0.6976, -0.6962, -0.7018, -0.7107,\n",
       "        -0.7243, -0.7438, -0.7642, -0.7764, -0.7763, -0.7638, -0.7412, -0.7219,\n",
       "        -0.7222, -0.7367, -0.7443, -0.7370, -0.7240, -0.7162, -0.7137, -0.7145,\n",
       "        -0.7213, -0.7330, -0.7422, -0.7497, -0.7622, -0.7738, -0.7707, -0.7528,\n",
       "        -0.7359, -0.7292, -0.7272, -0.7242, -0.7222, -0.7243, -0.7274, -0.7245,\n",
       "        -0.7188, -0.7152, -0.7084, -0.6907, -0.6715, -0.6640, -0.6695, -0.6764,\n",
       "        -0.6742, -0.6624, -0.6531, -0.6574, -0.6725, -0.6854, -0.6885, -0.6840,\n",
       "        -0.6745, -0.6655, -0.6647, -0.6698, -0.6678, -0.6485, -0.6216, -0.6009,\n",
       "        -0.5884, -0.5741, -0.5593, -0.5559, -0.5645, -0.5642, -0.5413, -0.5036,\n",
       "        -0.4714, -0.4474, -0.4241, -0.4110, -0.4254, -0.4538, -0.4701, -0.4669,\n",
       "        -0.4540, -0.4372, -0.4193, -0.4005, -0.3813, -0.3617, -0.3419, -0.3223,\n",
       "        -0.3031, -0.2845, -0.2668, -0.2490, -0.2282, -0.2004, -0.1676, -0.1407,\n",
       "        -0.1291, -0.1322, -0.1355, -0.1303, -0.1259, -0.1333, -0.1381, -0.1209,\n",
       "        -0.0884, -0.0614, -0.0355, -0.0062])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<train_gan.EuXFELCurrentDataModule at 0x28fd13f40>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module = EuXFELCurrentDataModule(batch_size=64, normalize=True)\n",
    "data_module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.setup(stage=\"fit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x28fd13a30>, 400)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = data_module.train_dataloader()\n",
    "data_loader, len(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x28fd13e50>, 50)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = data_module.val_dataloader()\n",
    "data_loader, len(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x28fd134f0>, 50)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = data_module.test_dataloader()\n",
    "data_loader, len(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spectral-vd-euxfel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
