{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from train_gan import (\n",
    "    Critic,\n",
    "    EuXFELCurrentDataModule,\n",
    "    EuXFELCurrentDataset,\n",
    "    Generator,\n",
    "    ConvolutionalDecoder,\n",
    "    ConvolutionalEncoder,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalEncoder(\n",
       "  (convnet): Sequential(\n",
       "    (0): Conv1d(1, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=960, out_features=100, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formfactor_encoder = ConvolutionalEncoder(signal_dims=240, latent_dims=10)\n",
    "formfactor_encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded = tensor([[ 0.0735,  0.0666,  0.1148, -0.0146,  0.0067, -0.0111,  0.1087, -0.1036,\n",
      "          0.1379,  0.0438],\n",
      "        [ 0.0734,  0.0672,  0.1120, -0.0131,  0.0072, -0.0098,  0.1079, -0.1054,\n",
      "          0.1385,  0.0463],\n",
      "        [ 0.0733,  0.0632,  0.1110, -0.0153,  0.0064, -0.0092,  0.1070, -0.1028,\n",
      "          0.1366,  0.0457]], grad_fn=<AddmmBackward0>)\n",
      "encoded.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "formfactor = torch.rand(3, 240)\n",
    "encoded = formfactor_encoder(formfactor)\n",
    "print(f\"{encoded = }\")\n",
    "print(f\"{encoded.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalEncoder(\n",
       "  (convnet): Sequential(\n",
       "    (0): Conv1d(1, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=1216, out_features=100, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_encoder = ConvolutionalEncoder(signal_dims=300, latent_dims=10)\n",
    "current_encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded = tensor([[ 0.0178, -0.0527,  0.0861, -0.0232,  0.0782, -0.0730, -0.1707, -0.0686,\n",
      "         -0.1039, -0.0677],\n",
      "        [ 0.0183, -0.0512,  0.0877, -0.0220,  0.0779, -0.0746, -0.1730, -0.0685,\n",
      "         -0.1057, -0.0651],\n",
      "        [ 0.0170, -0.0521,  0.0877, -0.0247,  0.0781, -0.0722, -0.1686, -0.0654,\n",
      "         -0.1055, -0.0672]], grad_fn=<AddmmBackward0>)\n",
      "encoded.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "current_profile = torch.rand(3, 300)\n",
    "encoded = current_encoder(current_profile)\n",
    "print(f\"{encoded = }\")\n",
    "print(f\"{encoded.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalDecoder(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=50, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=50, out_features=100, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=100, out_features=1216, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (unflatten): Unflatten(dim=1, unflattened_size=(32, 38))\n",
       "  (convnet): Sequential(\n",
       "    (0): ConvTranspose1d(32, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): ConvTranspose1d(16, 8, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): ConvTranspose1d(8, 1, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_decoder = ConvolutionalDecoder(latent_dims=10 + 5 + 1, signal_dims=300)\n",
    "current_decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_decoder.parameters().__next__().requires_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded = tensor([[0.0000, 0.0349, 0.0000, 0.0194, 0.0000, 0.0282, 0.0000, 0.0298, 0.0000,\n",
      "         0.0380, 0.0000, 0.0375, 0.0000, 0.0315, 0.0000, 0.0336, 0.0000, 0.0274,\n",
      "         0.0000, 0.0502, 0.0000, 0.0182, 0.0000, 0.0306, 0.0000, 0.0228, 0.0000,\n",
      "         0.0276, 0.0000, 0.0306, 0.0000, 0.0108, 0.0000, 0.0286, 0.0000, 0.0223,\n",
      "         0.0000, 0.0272, 0.0000, 0.0438, 0.0000, 0.0344, 0.0000, 0.0462, 0.0000,\n",
      "         0.0307, 0.0000, 0.0172, 0.0000, 0.0312, 0.0000, 0.0508, 0.0000, 0.0385,\n",
      "         0.0000, 0.0413, 0.0000, 0.0497, 0.0000, 0.0648, 0.0000, 0.0441, 0.0000,\n",
      "         0.0163, 0.0000, 0.0232, 0.0000, 0.0155, 0.0000, 0.0337, 0.0000, 0.0220,\n",
      "         0.0000, 0.0176, 0.0000, 0.0289, 0.0000, 0.0290, 0.0000, 0.0356, 0.0000,\n",
      "         0.0181, 0.0000, 0.0204, 0.0000, 0.0208, 0.0000, 0.0299, 0.0000, 0.0115,\n",
      "         0.0000, 0.0244, 0.0000, 0.0150, 0.0000, 0.0333, 0.0000, 0.0376, 0.0000,\n",
      "         0.0253, 0.0000, 0.0178, 0.0000, 0.0024, 0.0000, 0.0226, 0.0000, 0.0184,\n",
      "         0.0000, 0.0388, 0.0000, 0.0572, 0.0000, 0.0401, 0.0000, 0.0316, 0.0000,\n",
      "         0.0238, 0.0000, 0.0180, 0.0000, 0.0234, 0.0000, 0.0337, 0.0000, 0.0212,\n",
      "         0.0000, 0.0093, 0.0000, 0.0253, 0.0000, 0.0364, 0.0000, 0.0142, 0.0000,\n",
      "         0.0295, 0.0000, 0.0277, 0.0000, 0.0349, 0.0000, 0.0331, 0.0000, 0.0352,\n",
      "         0.0000, 0.0293, 0.0000, 0.0243, 0.0000, 0.0149, 0.0000, 0.0367, 0.0000,\n",
      "         0.0272, 0.0000, 0.0200, 0.0000, 0.0278, 0.0000, 0.0336, 0.0000, 0.0319,\n",
      "         0.0000, 0.0383, 0.0000, 0.0172, 0.0000, 0.0000, 0.0000, 0.0231, 0.0000,\n",
      "         0.0233, 0.0000, 0.0263, 0.0000, 0.0168, 0.0000, 0.0314, 0.0000, 0.0288,\n",
      "         0.0000, 0.0385, 0.0000, 0.0432, 0.0000, 0.0173, 0.0000, 0.0203, 0.0000,\n",
      "         0.0261, 0.0000, 0.0100, 0.0000, 0.0280, 0.0000, 0.0314, 0.0000, 0.0374,\n",
      "         0.0000, 0.0495, 0.0000, 0.0240, 0.0000, 0.0185, 0.0000, 0.0276, 0.0000,\n",
      "         0.0182, 0.0000, 0.0283, 0.0000, 0.0377, 0.0000, 0.0270, 0.0000, 0.0471,\n",
      "         0.0000, 0.0250, 0.0000, 0.0227, 0.0000, 0.0267, 0.0000, 0.0421, 0.0000,\n",
      "         0.0293, 0.0000, 0.0200, 0.0000, 0.0310, 0.0000, 0.0305, 0.0000, 0.0200,\n",
      "         0.0000, 0.0172, 0.0000, 0.0251, 0.0000, 0.0192, 0.0000, 0.0189, 0.0000,\n",
      "         0.0235, 0.0000, 0.0119, 0.0000, 0.0316, 0.0000, 0.0314, 0.0000, 0.0244,\n",
      "         0.0000, 0.0307, 0.0000, 0.0203, 0.0000, 0.0243, 0.0000, 0.0047, 0.0000,\n",
      "         0.0266, 0.0000, 0.0324, 0.0000, 0.0367, 0.0000, 0.0244, 0.0000, 0.0261,\n",
      "         0.0000, 0.0164, 0.0000, 0.0212, 0.0000, 0.0326, 0.0000, 0.0230, 0.0000,\n",
      "         0.0032, 0.0000, 0.0274, 0.0000, 0.0126, 0.0000, 0.0334, 0.0000, 0.0365,\n",
      "         0.0000, 0.0308, 0.0000, 0.0246, 0.0000, 0.0232, 0.0000, 0.0224, 0.0000,\n",
      "         0.0479, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0409, 0.0000, 0.0269, 0.0000, 0.0315, 0.0000, 0.0254, 0.0000,\n",
      "         0.0369, 0.0000, 0.0354, 0.0000, 0.0280, 0.0000, 0.0246, 0.0000, 0.0248,\n",
      "         0.0000, 0.0492, 0.0000, 0.0166, 0.0000, 0.0309, 0.0000, 0.0346, 0.0000,\n",
      "         0.0398, 0.0000, 0.0341, 0.0000, 0.0265, 0.0000, 0.0336, 0.0000, 0.0273,\n",
      "         0.0000, 0.0317, 0.0000, 0.0457, 0.0000, 0.0314, 0.0000, 0.0474, 0.0000,\n",
      "         0.0357, 0.0000, 0.0156, 0.0000, 0.0314, 0.0000, 0.0544, 0.0000, 0.0375,\n",
      "         0.0000, 0.0370, 0.0000, 0.0502, 0.0000, 0.0689, 0.0000, 0.0325, 0.0000,\n",
      "         0.0000, 0.0000, 0.0240, 0.0000, 0.0044, 0.0000, 0.0367, 0.0000, 0.0152,\n",
      "         0.0000, 0.0146, 0.0000, 0.0265, 0.0000, 0.0273, 0.0000, 0.0156, 0.0000,\n",
      "         0.0082, 0.0000, 0.0067, 0.0000, 0.0181, 0.0000, 0.0248, 0.0000, 0.0103,\n",
      "         0.0000, 0.0311, 0.0000, 0.0163, 0.0000, 0.0109, 0.0000, 0.0209, 0.0000,\n",
      "         0.0245, 0.0000, 0.0185, 0.0000, 0.0000, 0.0000, 0.0198, 0.0000, 0.0149,\n",
      "         0.0000, 0.0335, 0.0000, 0.0596, 0.0000, 0.0404, 0.0000, 0.0314, 0.0000,\n",
      "         0.0182, 0.0000, 0.0044, 0.0000, 0.0181, 0.0000, 0.0322, 0.0000, 0.0227,\n",
      "         0.0000, 0.0016, 0.0000, 0.0221, 0.0000, 0.0339, 0.0000, 0.0114, 0.0000,\n",
      "         0.0261, 0.0000, 0.0300, 0.0000, 0.0321, 0.0000, 0.0353, 0.0000, 0.0352,\n",
      "         0.0000, 0.0331, 0.0000, 0.0288, 0.0000, 0.0120, 0.0000, 0.0404, 0.0000,\n",
      "         0.0275, 0.0000, 0.0183, 0.0000, 0.0271, 0.0000, 0.0348, 0.0000, 0.0355,\n",
      "         0.0000, 0.0323, 0.0000, 0.0156, 0.0000, 0.0000, 0.0000, 0.0204, 0.0000,\n",
      "         0.0217, 0.0000, 0.0205, 0.0000, 0.0009, 0.0000, 0.0298, 0.0000, 0.0246,\n",
      "         0.0000, 0.0346, 0.0000, 0.0404, 0.0000, 0.0169, 0.0000, 0.0242, 0.0000,\n",
      "         0.0285, 0.0000, 0.0172, 0.0000, 0.0279, 0.0000, 0.0311, 0.0000, 0.0353,\n",
      "         0.0000, 0.0554, 0.0000, 0.0320, 0.0000, 0.0286, 0.0000, 0.0250, 0.0000,\n",
      "         0.0221, 0.0000, 0.0290, 0.0000, 0.0332, 0.0000, 0.0261, 0.0000, 0.0427,\n",
      "         0.0000, 0.0258, 0.0000, 0.0263, 0.0000, 0.0286, 0.0000, 0.0398, 0.0000,\n",
      "         0.0288, 0.0000, 0.0176, 0.0000, 0.0271, 0.0000, 0.0293, 0.0000, 0.0111,\n",
      "         0.0000, 0.0130, 0.0000, 0.0201, 0.0000, 0.0023, 0.0000, 0.0177, 0.0000,\n",
      "         0.0169, 0.0000, 0.0074, 0.0000, 0.0185, 0.0000, 0.0255, 0.0000, 0.0204,\n",
      "         0.0000, 0.0269, 0.0000, 0.0108, 0.0000, 0.0293, 0.0000, 0.0074, 0.0000,\n",
      "         0.0258, 0.0000, 0.0330, 0.0000, 0.0384, 0.0000, 0.0338, 0.0000, 0.0224,\n",
      "         0.0000, 0.0113, 0.0000, 0.0142, 0.0000, 0.0280, 0.0000, 0.0163, 0.0000,\n",
      "         0.0000, 0.0000, 0.0239, 0.0000, 0.0101, 0.0000, 0.0324, 0.0000, 0.0546,\n",
      "         0.0000, 0.0335, 0.0000, 0.0213, 0.0000, 0.0238, 0.0000, 0.0181, 0.0000,\n",
      "         0.0473, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0351, 0.0000, 0.0263, 0.0000, 0.0308, 0.0000, 0.0330, 0.0000,\n",
      "         0.0356, 0.0000, 0.0367, 0.0000, 0.0271, 0.0000, 0.0295, 0.0000, 0.0246,\n",
      "         0.0000, 0.0450, 0.0000, 0.0169, 0.0000, 0.0312, 0.0000, 0.0302, 0.0000,\n",
      "         0.0329, 0.0000, 0.0285, 0.0000, 0.0303, 0.0000, 0.0313, 0.0000, 0.0298,\n",
      "         0.0000, 0.0322, 0.0000, 0.0441, 0.0000, 0.0298, 0.0000, 0.0486, 0.0000,\n",
      "         0.0323, 0.0000, 0.0116, 0.0000, 0.0292, 0.0000, 0.0507, 0.0000, 0.0390,\n",
      "         0.0000, 0.0369, 0.0000, 0.0559, 0.0000, 0.0715, 0.0000, 0.0264, 0.0000,\n",
      "         0.0000, 0.0000, 0.0283, 0.0000, 0.0059, 0.0000, 0.0373, 0.0000, 0.0293,\n",
      "         0.0000, 0.0128, 0.0000, 0.0260, 0.0000, 0.0278, 0.0000, 0.0116, 0.0000,\n",
      "         0.0117, 0.0000, 0.0152, 0.0000, 0.0185, 0.0000, 0.0261, 0.0000, 0.0124,\n",
      "         0.0000, 0.0300, 0.0000, 0.0148, 0.0000, 0.0104, 0.0000, 0.0153, 0.0000,\n",
      "         0.0165, 0.0000, 0.0191, 0.0000, 0.0000, 0.0000, 0.0246, 0.0000, 0.0197,\n",
      "         0.0000, 0.0354, 0.0000, 0.0536, 0.0000, 0.0393, 0.0000, 0.0254, 0.0000,\n",
      "         0.0177, 0.0000, 0.0070, 0.0000, 0.0129, 0.0000, 0.0285, 0.0000, 0.0218,\n",
      "         0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.0375, 0.0000, 0.0149, 0.0000,\n",
      "         0.0247, 0.0000, 0.0300, 0.0000, 0.0293, 0.0000, 0.0329, 0.0000, 0.0342,\n",
      "         0.0000, 0.0290, 0.0000, 0.0341, 0.0000, 0.0184, 0.0000, 0.0387, 0.0000,\n",
      "         0.0284, 0.0000, 0.0171, 0.0000, 0.0255, 0.0000, 0.0279, 0.0000, 0.0373,\n",
      "         0.0000, 0.0289, 0.0000, 0.0171, 0.0000, 0.0000, 0.0000, 0.0209, 0.0000,\n",
      "         0.0178, 0.0000, 0.0205, 0.0000, 0.0126, 0.0000, 0.0331, 0.0000, 0.0282,\n",
      "         0.0000, 0.0345, 0.0000, 0.0433, 0.0000, 0.0167, 0.0000, 0.0312, 0.0000,\n",
      "         0.0255, 0.0000, 0.0000, 0.0000, 0.0216, 0.0000, 0.0243, 0.0000, 0.0347,\n",
      "         0.0000, 0.0515, 0.0000, 0.0329, 0.0000, 0.0274, 0.0000, 0.0251, 0.0000,\n",
      "         0.0200, 0.0000, 0.0249, 0.0000, 0.0296, 0.0000, 0.0249, 0.0000, 0.0416,\n",
      "         0.0000, 0.0252, 0.0000, 0.0255, 0.0000, 0.0300, 0.0000, 0.0459, 0.0000,\n",
      "         0.0331, 0.0000, 0.0255, 0.0000, 0.0274, 0.0000, 0.0245, 0.0000, 0.0087,\n",
      "         0.0000, 0.0094, 0.0000, 0.0178, 0.0000, 0.0000, 0.0000, 0.0180, 0.0000,\n",
      "         0.0227, 0.0000, 0.0107, 0.0000, 0.0219, 0.0000, 0.0309, 0.0000, 0.0308,\n",
      "         0.0000, 0.0296, 0.0000, 0.0035, 0.0000, 0.0267, 0.0000, 0.0075, 0.0000,\n",
      "         0.0280, 0.0000, 0.0448, 0.0000, 0.0392, 0.0000, 0.0433, 0.0000, 0.0262,\n",
      "         0.0000, 0.0211, 0.0000, 0.0206, 0.0000, 0.0337, 0.0000, 0.0208, 0.0000,\n",
      "         0.0000, 0.0000, 0.0229, 0.0000, 0.0141, 0.0000, 0.0300, 0.0000, 0.0531,\n",
      "         0.0000, 0.0347, 0.0000, 0.0234, 0.0000, 0.0255, 0.0000, 0.0170, 0.0000,\n",
      "         0.0499, 0.0000, 0.0000]], grad_fn=<SqueezeBackward1>)\n",
      "decoded.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "latent = torch.rand(3, 10 + 5 + 1)\n",
    "decoded = current_decoder(latent)\n",
    "print(f\"{decoded = }\")\n",
    "print(f\"{decoded.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalDecoder(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=50, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=50, out_features=100, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=100, out_features=960, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (unflatten): Unflatten(dim=1, unflattened_size=(32, 30))\n",
       "  (convnet): Sequential(\n",
       "    (0): ConvTranspose1d(32, 16, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): ConvTranspose1d(16, 8, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): ConvTranspose1d(8, 1, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formfactor_decoder = ConvolutionalDecoder(latent_dims=10 + 5 + 1, signal_dims=240)\n",
    "formfactor_decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded = tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "decoded.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "latent = torch.rand(3, 10 + 5 + 1)\n",
    "decoded = formfactor_decoder(latent)\n",
    "print(f\"{decoded = }\")\n",
    "print(f\"{decoded.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (formfactor_encoder): ConvolutionalEncoder(\n",
       "    (convnet): Sequential(\n",
       "      (0): Conv1d(1, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=960, out_features=100, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (current_decoder): ConvolutionalDecoder(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=50, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=50, out_features=100, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=100, out_features=1216, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (unflatten): Unflatten(dim=1, unflattened_size=(32, 38))\n",
       "    (convnet): Sequential(\n",
       "      (0): ConvTranspose1d(32, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): ConvTranspose1d(16, 8, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): ConvTranspose1d(8, 1, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "      (5): ReLU()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = Generator()\n",
    "generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.parameters().__next__().requires_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_profile.size() = torch.Size([3, 300])\n",
      "current_profile.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "formfactor = torch.rand(3, 240)\n",
    "rf_settings = torch.rand(3, 5)\n",
    "bunch_length = torch.rand(3, 1)\n",
    "\n",
    "current_profile = generator(formfactor, rf_settings, bunch_length)\n",
    "print(f\"{current_profile.size() = }\")\n",
    "print(f\"{current_profile.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Critic(\n",
       "  (formfactor_encoder): ConvolutionalEncoder(\n",
       "    (convnet): Sequential(\n",
       "      (0): Conv1d(1, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=960, out_features=100, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (current_encoder): ConvolutionalEncoder(\n",
       "    (convnet): Sequential(\n",
       "      (0): Conv1d(1, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=1216, out_features=100, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=26, out_features=50, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=50, out_features=20, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=20, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic = Critic()\n",
    "critic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "critique = tensor([[-0.0222],\n",
      "        [-0.0188],\n",
      "        [-0.0079]], grad_fn=<AddmmBackward0>)\n",
      "critique.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "critique = critic(current_profile, formfactor, rf_settings, bunch_length)\n",
    "print(f\"{critique = }\")\n",
    "print(f\"{critique.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<train_gan.EuXFELCurrentDataset at 0x2aa32e430>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = EuXFELCurrentDataset(normalize=True)\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25600"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(formfactor, rf_settings, bunch_length), current_profile = dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8967, -0.0496,  0.6493,  0.6142,  0.6210,  0.3280,  0.4514,  0.7230,\n",
       "         0.5122,  0.4343,  0.7586,  0.7439,  0.7516,  0.7016,  0.6730, -0.3678,\n",
       "         0.7603,  0.7358,  0.7098,  0.7879,  0.7730,  0.9261,  0.8817,  0.8326,\n",
       "         0.8834,  0.8499,  0.8204,  0.8329,  0.8822,  0.9108,  0.8027,  1.0196,\n",
       "         0.9109,  0.6966,  0.7671,  0.9020,  0.8463,  0.9784,  0.8875,  0.9628,\n",
       "         1.0164,  1.0460,  1.0049,  1.0713,  1.0758,  1.1035,  1.0718,  1.0805,\n",
       "         1.1297,  1.1424,  1.1248,  1.1508,  1.1933,  1.2206,  1.2327,  1.2506,\n",
       "         1.2511,  1.2965,  1.3434,  1.3815,  1.5425,  1.1233,  1.4732,  1.3150,\n",
       "         1.4260,  1.4542,  1.3917,  1.4061,  1.4489,  1.4558,  1.4331,  1.4687,\n",
       "         1.5044,  1.5263,  1.4788,  1.5456,  1.5517,  1.5728,  1.6156,  1.6282,\n",
       "         1.6280,  1.6681,  1.6934,  1.7095,  1.7405,  1.7749,  1.7983,  1.8291,\n",
       "         1.8542,  1.8679,  1.7163,  1.8633,  1.7904,  1.8032,  1.7841,  1.8590,\n",
       "         1.8147,  1.8813,  1.8448,  1.8957,  1.9264,  1.9463,  1.9478,  1.9649,\n",
       "         1.9585,  1.9943,  2.0212,  2.0573,  2.0593,  2.0769,  2.1007,  2.1120,\n",
       "         2.1341,  2.1607,  2.1794,  2.1985,  2.2186,  2.2349,  2.2524,  2.2569,\n",
       "         2.1857,  2.1657,  2.2057,  2.2196,  2.2435,  2.2523,  2.2578,  2.2663,\n",
       "         2.2680,  2.2827,  2.2845,  2.2985,  2.2866,  2.3009,  2.2994,  1.9667,\n",
       "         2.2991,  2.3010,  2.3025,  2.2901,  2.2860,  2.2792,  2.2695,  2.2467,\n",
       "         2.2248,  2.1982,  2.1597,  2.1174,  2.0646,  1.9337,  1.9511,  1.9810,\n",
       "         1.9728,  1.9497,  1.8025,  1.9672,  1.9438,  1.9478,  1.9355,  1.8930,\n",
       "         1.8533,  1.8392,  1.8147,  1.7740,  1.7439,  1.6658,  1.5800,  1.5412,\n",
       "         1.4963,  1.4461,  1.3541,  1.2666,  1.1657,  1.0379,  0.9078,  0.7596,\n",
       "         0.5961,  0.4213,  0.2312,  0.0592, -0.0425, -0.6558,  0.0230, -0.0076,\n",
       "        -0.0577,  0.0189,  0.0527, -0.0691,  0.2239,  0.0216,  0.2083,  0.2729,\n",
       "         0.3741,  0.4513,  0.5714,  0.7138,  0.8365,  0.9838,  1.1424,  1.2839,\n",
       "         1.4478,  1.6077,  1.7772,  1.9311,  2.0646,  2.1667,  2.2557,  2.2817,\n",
       "         2.2374,  1.7973,  1.8790,  1.8666,  2.0043,  1.9758,  1.7275,  1.9254,\n",
       "         1.7280,  1.9347,  1.8508,  1.7824,  1.7061,  1.5175,  1.4270,  1.2001,\n",
       "         1.1831,  0.9188,  0.5856, -0.3044, -0.5467, -1.0091,  1.0257,  0.1825,\n",
       "         1.1466,  1.1963,  1.8687,  2.2996,  2.5841,  2.4850,  1.2992, -0.4940])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formfactor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3616,  1.7155, -1.3814, -0.2878, -0.9114])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0020])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bunch_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4532, -0.4376, -0.4221, -0.4059, -0.3925, -0.3846, -0.3829, -0.3856,\n",
       "        -0.3896, -0.3934, -0.3964, -0.3985, -0.3999, -0.4005, -0.4007, -0.4005,\n",
       "        -0.4002, -0.4000, -0.3998, -0.3997, -0.3998, -0.4000, -0.4004, -0.4008,\n",
       "        -0.4013, -0.4015, -0.4019, -0.4037, -0.4074, -0.4126, -0.4183, -0.4243,\n",
       "        -0.4309, -0.4379, -0.4454, -0.4532, -0.4611, -0.4690, -0.4769, -0.4847,\n",
       "        -0.4922, -0.4992, -0.5053, -0.5109, -0.5174, -0.5251, -0.5326, -0.5390,\n",
       "        -0.5442, -0.5495, -0.5561, -0.5640, -0.5720, -0.5795, -0.5863, -0.5925,\n",
       "        -0.5986, -0.6056, -0.6132, -0.6202, -0.6254, -0.6270, -0.6191, -0.5927,\n",
       "        -0.5399, -0.4538, -0.3326, -0.1847, -0.0210,  0.1518,  0.3331,  0.5266,\n",
       "         0.7321,  0.9510,  1.1886,  1.4529,  1.7598,  2.1348,  2.5822,  3.0652,\n",
       "         3.4982,  3.7927,  3.9313,  3.9726,  4.0022,  4.0659,  4.1547,  4.2426,\n",
       "         4.3249,  4.3937,  4.4215,  4.3959,  4.3457,  4.2917,  4.2158,  4.0946,\n",
       "         3.9514,  3.8225,  3.7079,  3.5867,  3.4532,  3.3099,  3.1694,  3.0557,\n",
       "         2.9746,  2.9051,  2.8194,  2.7018,  2.5561,  2.4017,  2.2581,  2.1447,\n",
       "         2.0801,  2.0720,  2.1067,  2.1486,  2.1505,  2.0881,  1.9713,  1.8359,\n",
       "         1.7282,  1.6745,  1.6778,  1.7232,  1.7774,  1.8069,  1.8024,  1.7797,\n",
       "         1.7557,  1.7236,  1.6751,  1.6241,  1.5815,  1.5364,  1.4884,  1.4679,\n",
       "         1.4965,  1.5676,  1.6521,  1.7100,  1.7249,  1.7177,  1.7107,  1.6953,\n",
       "         1.6597,  1.6152,  1.5786,  1.5575,  1.5610,  1.6003,  1.6648,  1.7279,\n",
       "         1.7637,  1.7662,  1.7495,  1.7463,  1.7902,  1.8794,  1.9721,  2.0216,\n",
       "         2.0128,  1.9533,  1.8551,  1.7426,  1.6368,  1.5421,  1.4674,  1.4188,\n",
       "         1.3756,  1.3139,  1.2306,  1.1324,  1.0083,  0.8366,  0.6071,  0.3368,\n",
       "         0.0548, -0.2003, -0.3942, -0.5172, -0.5870, -0.6258, -0.6435, -0.6424,\n",
       "        -0.6362, -0.6426, -0.6649, -0.6914, -0.7074, -0.7141, -0.7232, -0.7362,\n",
       "        -0.7420, -0.7369, -0.7243, -0.7088, -0.6976, -0.6962, -0.7018, -0.7107,\n",
       "        -0.7243, -0.7438, -0.7642, -0.7764, -0.7763, -0.7638, -0.7412, -0.7219,\n",
       "        -0.7222, -0.7367, -0.7443, -0.7370, -0.7240, -0.7162, -0.7137, -0.7145,\n",
       "        -0.7213, -0.7330, -0.7422, -0.7497, -0.7622, -0.7738, -0.7707, -0.7528,\n",
       "        -0.7359, -0.7292, -0.7272, -0.7242, -0.7222, -0.7243, -0.7274, -0.7245,\n",
       "        -0.7188, -0.7152, -0.7084, -0.6907, -0.6715, -0.6640, -0.6695, -0.6764,\n",
       "        -0.6742, -0.6624, -0.6531, -0.6574, -0.6725, -0.6854, -0.6885, -0.6840,\n",
       "        -0.6745, -0.6655, -0.6647, -0.6698, -0.6678, -0.6485, -0.6216, -0.6009,\n",
       "        -0.5884, -0.5741, -0.5593, -0.5559, -0.5645, -0.5642, -0.5413, -0.5036,\n",
       "        -0.4714, -0.4474, -0.4241, -0.4110, -0.4254, -0.4538, -0.4701, -0.4669,\n",
       "        -0.4540, -0.4372, -0.4193, -0.4005, -0.3813, -0.3617, -0.3419, -0.3223,\n",
       "        -0.3031, -0.2845, -0.2668, -0.2490, -0.2282, -0.2004, -0.1676, -0.1407,\n",
       "        -0.1291, -0.1322, -0.1355, -0.1303, -0.1259, -0.1333, -0.1381, -0.1209,\n",
       "        -0.0884, -0.0614, -0.0355, -0.0062])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<train_gan.EuXFELCurrentDataModule at 0x2aa32e190>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module = EuXFELCurrentDataModule(batch_size=64, normalize=True)\n",
    "data_module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.setup(stage=\"fit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x2aa32e850>, 400)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = data_module.train_dataloader()\n",
    "data_loader, len(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x2aa32e130>, 50)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = data_module.val_dataloader()\n",
    "data_loader, len(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x2aa32e3d0>, 50)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = data_module.test_dataloader()\n",
    "data_loader, len(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spectral-vd-euxfel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
