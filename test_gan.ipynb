{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from train_gan import (\n",
    "    Critic,\n",
    "    EuXFELCurrentDataModule,\n",
    "    EuXFELCurrentDataset,\n",
    "    Generator,\n",
    "    ConvolutionalDecoder,\n",
    "    ConvolutionalEncoder,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalEncoder(\n",
       "  (convnet): Sequential(\n",
       "    (0): Conv1d(1, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=960, out_features=100, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formfactor_encoder = ConvolutionalEncoder(signal_dims=240, latent_dims=10)\n",
    "formfactor_encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded = tensor([[-0.0202,  0.0085, -0.0483,  0.1294, -0.1184,  0.0755,  0.1278,  0.0924,\n",
      "          0.1252,  0.0485],\n",
      "        [-0.0221,  0.0060, -0.0486,  0.1302, -0.1174,  0.0758,  0.1283,  0.0915,\n",
      "          0.1242,  0.0501],\n",
      "        [-0.0209,  0.0079, -0.0460,  0.1289, -0.1160,  0.0720,  0.1328,  0.0942,\n",
      "          0.1250,  0.0492]], grad_fn=<AddmmBackward0>)\n",
      "encoded.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "formfactor = torch.rand(3, 240)\n",
    "encoded = formfactor_encoder(formfactor)\n",
    "print(f\"{encoded = }\")\n",
    "print(f\"{encoded.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalEncoder(\n",
       "  (convnet): Sequential(\n",
       "    (0): Conv1d(1, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=1216, out_features=100, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_encoder = ConvolutionalEncoder(signal_dims=300, latent_dims=10)\n",
    "current_encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded = tensor([[ 0.0613,  0.1177,  0.0679, -0.0781, -0.0600, -0.1421,  0.0401,  0.0310,\n",
      "         -0.0717,  0.1091],\n",
      "        [ 0.0642,  0.1166,  0.0718, -0.0801, -0.0579, -0.1412,  0.0397,  0.0290,\n",
      "         -0.0726,  0.1109],\n",
      "        [ 0.0627,  0.1174,  0.0705, -0.0794, -0.0590, -0.1400,  0.0387,  0.0319,\n",
      "         -0.0713,  0.1071]], grad_fn=<AddmmBackward0>)\n",
      "encoded.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "current_profile = torch.rand(3, 300)\n",
    "encoded = current_encoder(current_profile)\n",
    "print(f\"{encoded = }\")\n",
    "print(f\"{encoded.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalDecoder(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=50, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=50, out_features=100, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=100, out_features=1216, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (unflatten): Unflatten(dim=1, unflattened_size=(32, 38))\n",
       "  (convnet): Sequential(\n",
       "    (0): ConvTranspose1d(32, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): ConvTranspose1d(16, 8, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): ConvTranspose1d(8, 1, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_decoder = ConvolutionalDecoder(latent_dims=10 + 5 + 1, signal_dims=300)\n",
    "current_decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_decoder.parameters().__next__().requires_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded = tensor([[0.4040, 0.3124, 0.4293, 0.2998, 0.4077, 0.3106, 0.4098, 0.3027, 0.4075,\n",
      "         0.3148, 0.4050, 0.3123, 0.4012, 0.2957, 0.4189, 0.2879, 0.4110, 0.3018,\n",
      "         0.4206, 0.3037, 0.4004, 0.2887, 0.4218, 0.2958, 0.4185, 0.2997, 0.4221,\n",
      "         0.3146, 0.4034, 0.3138, 0.4158, 0.2905, 0.3998, 0.2834, 0.4127, 0.3031,\n",
      "         0.4201, 0.2879, 0.4160, 0.3050, 0.4210, 0.2906, 0.4121, 0.3206, 0.3992,\n",
      "         0.3003, 0.4255, 0.2852, 0.4010, 0.3077, 0.4220, 0.3199, 0.4241, 0.2944,\n",
      "         0.4117, 0.2863, 0.4212, 0.2968, 0.4188, 0.2809, 0.4055, 0.2899, 0.4087,\n",
      "         0.2975, 0.4105, 0.2957, 0.4150, 0.3075, 0.4007, 0.2993, 0.4166, 0.3020,\n",
      "         0.4013, 0.2934, 0.4215, 0.2989, 0.4151, 0.2988, 0.4196, 0.3130, 0.4130,\n",
      "         0.3046, 0.4178, 0.3044, 0.3997, 0.2983, 0.4170, 0.2820, 0.4122, 0.3025,\n",
      "         0.4049, 0.3138, 0.4039, 0.2959, 0.4202, 0.2899, 0.4142, 0.3072, 0.4231,\n",
      "         0.2966, 0.4047, 0.2887, 0.4104, 0.2863, 0.4183, 0.3091, 0.4203, 0.3005,\n",
      "         0.4026, 0.2910, 0.4157, 0.2936, 0.4052, 0.3015, 0.4131, 0.3173, 0.4172,\n",
      "         0.2815, 0.4193, 0.2848, 0.4093, 0.3108, 0.4094, 0.3105, 0.4107, 0.2847,\n",
      "         0.4189, 0.2783, 0.4039, 0.3111, 0.4258, 0.2894, 0.4004, 0.3077, 0.4166,\n",
      "         0.3107, 0.4098, 0.3081, 0.4279, 0.3060, 0.4038, 0.3032, 0.4214, 0.2980,\n",
      "         0.4052, 0.3033, 0.4225, 0.3009, 0.4259, 0.3020, 0.4086, 0.3266, 0.4122,\n",
      "         0.2853, 0.4206, 0.3011, 0.4036, 0.2815, 0.4185, 0.2977, 0.4032, 0.3017,\n",
      "         0.4153, 0.2948, 0.4095, 0.2982, 0.4284, 0.2976, 0.4025, 0.3041, 0.4126,\n",
      "         0.3031, 0.4146, 0.2781, 0.4257, 0.2873, 0.4098, 0.3078, 0.4171, 0.3043,\n",
      "         0.4195, 0.2902, 0.4062, 0.3033, 0.4112, 0.3055, 0.4277, 0.2958, 0.4127,\n",
      "         0.3048, 0.4115, 0.3101, 0.4042, 0.2974, 0.4226, 0.2969, 0.4302, 0.2861,\n",
      "         0.4162, 0.3034, 0.4147, 0.3085, 0.4188, 0.2983, 0.4021, 0.3001, 0.4125,\n",
      "         0.2935, 0.4040, 0.3070, 0.4192, 0.2860, 0.4149, 0.2998, 0.4200, 0.3181,\n",
      "         0.4035, 0.3135, 0.4153, 0.3068, 0.4123, 0.3045, 0.4170, 0.3028, 0.4022,\n",
      "         0.3120, 0.4210, 0.2942, 0.4084, 0.3065, 0.4132, 0.3065, 0.3998, 0.3062,\n",
      "         0.4237, 0.2887, 0.4061, 0.2995, 0.4244, 0.3114, 0.4067, 0.3049, 0.4196,\n",
      "         0.2974, 0.4129, 0.3042, 0.4264, 0.3032, 0.4037, 0.3163, 0.4178, 0.3163,\n",
      "         0.4037, 0.3061, 0.4187, 0.3023, 0.4026, 0.3056, 0.4190, 0.2996, 0.4031,\n",
      "         0.3042, 0.4178, 0.3043, 0.4060, 0.2897, 0.4179, 0.2821, 0.4067, 0.2929,\n",
      "         0.4301, 0.3018, 0.4115, 0.3123, 0.4137, 0.3341, 0.3978, 0.3048, 0.4215,\n",
      "         0.3037, 0.4144, 0.3015, 0.4092, 0.3163, 0.4237, 0.2944, 0.4159, 0.2941,\n",
      "         0.4210, 0.3052, 0.4102, 0.3047, 0.4121, 0.2805, 0.4134, 0.2928, 0.4120,\n",
      "         0.2939, 0.4154, 0.3558],\n",
      "        [0.4064, 0.3077, 0.4323, 0.2948, 0.4109, 0.3048, 0.4023, 0.3028, 0.4125,\n",
      "         0.3117, 0.4017, 0.3177, 0.4039, 0.2928, 0.4158, 0.2869, 0.4135, 0.3008,\n",
      "         0.4189, 0.2998, 0.4021, 0.2894, 0.4168, 0.2960, 0.4181, 0.2983, 0.4207,\n",
      "         0.3117, 0.4031, 0.3140, 0.4165, 0.2985, 0.3967, 0.2846, 0.4130, 0.2983,\n",
      "         0.4200, 0.2879, 0.4182, 0.3059, 0.4212, 0.2905, 0.4102, 0.3220, 0.4019,\n",
      "         0.2983, 0.4286, 0.2817, 0.4018, 0.3042, 0.4238, 0.3216, 0.4243, 0.2907,\n",
      "         0.4140, 0.2802, 0.4231, 0.3019, 0.4088, 0.2929, 0.4002, 0.2872, 0.4157,\n",
      "         0.2931, 0.4075, 0.2953, 0.4144, 0.3098, 0.4106, 0.2910, 0.4148, 0.2991,\n",
      "         0.4010, 0.2966, 0.4221, 0.3015, 0.4186, 0.2997, 0.4163, 0.3168, 0.4145,\n",
      "         0.3057, 0.4172, 0.3047, 0.3952, 0.3015, 0.4172, 0.2803, 0.4105, 0.3026,\n",
      "         0.4049, 0.3125, 0.4020, 0.3033, 0.4220, 0.2981, 0.4179, 0.3040, 0.4196,\n",
      "         0.2995, 0.4039, 0.2940, 0.4084, 0.2892, 0.4140, 0.2993, 0.4240, 0.2966,\n",
      "         0.3986, 0.2924, 0.4203, 0.2948, 0.4006, 0.3033, 0.4132, 0.3199, 0.4146,\n",
      "         0.2819, 0.4163, 0.2907, 0.4117, 0.3102, 0.4101, 0.3056, 0.4098, 0.2805,\n",
      "         0.4168, 0.2725, 0.4090, 0.3088, 0.4303, 0.2824, 0.4019, 0.3038, 0.4119,\n",
      "         0.3154, 0.4133, 0.3079, 0.4294, 0.3038, 0.4045, 0.2997, 0.4182, 0.2996,\n",
      "         0.4052, 0.3014, 0.4224, 0.2985, 0.4254, 0.3063, 0.3997, 0.3334, 0.4091,\n",
      "         0.2886, 0.4161, 0.3115, 0.3985, 0.2898, 0.4254, 0.2951, 0.4036, 0.2985,\n",
      "         0.4190, 0.2942, 0.4067, 0.3038, 0.4260, 0.2928, 0.4024, 0.3020, 0.4102,\n",
      "         0.2981, 0.4193, 0.2839, 0.4219, 0.2968, 0.4087, 0.3050, 0.4196, 0.3030,\n",
      "         0.4204, 0.2943, 0.4049, 0.2970, 0.4084, 0.3012, 0.4372, 0.2906, 0.4121,\n",
      "         0.3125, 0.4059, 0.3217, 0.4004, 0.3034, 0.4235, 0.2972, 0.4269, 0.2798,\n",
      "         0.4201, 0.2912, 0.4145, 0.3062, 0.4186, 0.2958, 0.4014, 0.2969, 0.4130,\n",
      "         0.2970, 0.4056, 0.3074, 0.4209, 0.2888, 0.4131, 0.3019, 0.4180, 0.3223,\n",
      "         0.4017, 0.3140, 0.4145, 0.3042, 0.4126, 0.2989, 0.4180, 0.3040, 0.4047,\n",
      "         0.3114, 0.4221, 0.3034, 0.4037, 0.3124, 0.4148, 0.3114, 0.3957, 0.3123,\n",
      "         0.4213, 0.2856, 0.4058, 0.2987, 0.4209, 0.3103, 0.4063, 0.3061, 0.4189,\n",
      "         0.2985, 0.4084, 0.3060, 0.4257, 0.3000, 0.4023, 0.3167, 0.4169, 0.3177,\n",
      "         0.3966, 0.3114, 0.4194, 0.3051, 0.4040, 0.3028, 0.4185, 0.2923, 0.4065,\n",
      "         0.3019, 0.4229, 0.3033, 0.4082, 0.2887, 0.4185, 0.2813, 0.4037, 0.2955,\n",
      "         0.4302, 0.3024, 0.4128, 0.3077, 0.4175, 0.3248, 0.4065, 0.3006, 0.4228,\n",
      "         0.3100, 0.4185, 0.3007, 0.4096, 0.3191, 0.4215, 0.2911, 0.4140, 0.2919,\n",
      "         0.4198, 0.3087, 0.4079, 0.3044, 0.4142, 0.2787, 0.4094, 0.2933, 0.4148,\n",
      "         0.2919, 0.4149, 0.3527],\n",
      "        [0.4046, 0.3142, 0.4327, 0.2961, 0.4039, 0.3078, 0.4062, 0.3033, 0.4069,\n",
      "         0.3109, 0.4046, 0.3134, 0.4065, 0.2907, 0.4150, 0.2885, 0.4107, 0.2997,\n",
      "         0.4149, 0.3058, 0.4012, 0.2882, 0.4185, 0.2901, 0.4161, 0.2975, 0.4207,\n",
      "         0.3086, 0.4004, 0.3079, 0.4171, 0.2938, 0.3990, 0.2834, 0.4129, 0.3116,\n",
      "         0.4235, 0.2878, 0.4179, 0.3040, 0.4198, 0.2915, 0.4107, 0.3160, 0.4024,\n",
      "         0.2983, 0.4315, 0.2845, 0.3984, 0.3099, 0.4254, 0.3168, 0.4212, 0.2893,\n",
      "         0.4140, 0.2816, 0.4264, 0.3048, 0.4099, 0.2918, 0.4021, 0.2923, 0.4232,\n",
      "         0.2891, 0.4066, 0.3037, 0.4173, 0.3058, 0.4041, 0.3051, 0.4124, 0.3036,\n",
      "         0.4002, 0.2867, 0.4230, 0.3006, 0.4198, 0.2980, 0.4165, 0.3178, 0.4143,\n",
      "         0.3028, 0.4184, 0.3114, 0.3966, 0.3065, 0.4170, 0.2818, 0.4093, 0.3026,\n",
      "         0.4056, 0.3155, 0.4029, 0.3068, 0.4212, 0.2908, 0.4138, 0.3060, 0.4194,\n",
      "         0.2913, 0.4072, 0.2939, 0.4112, 0.2929, 0.4135, 0.3055, 0.4184, 0.3030,\n",
      "         0.4039, 0.2944, 0.4174, 0.2977, 0.4072, 0.3045, 0.4135, 0.3112, 0.4158,\n",
      "         0.2786, 0.4103, 0.2902, 0.4154, 0.3081, 0.4113, 0.3071, 0.4077, 0.2852,\n",
      "         0.4160, 0.2822, 0.4046, 0.3058, 0.4235, 0.2930, 0.4068, 0.3047, 0.4126,\n",
      "         0.3108, 0.4114, 0.3049, 0.4267, 0.2987, 0.4112, 0.2959, 0.4172, 0.3045,\n",
      "         0.4093, 0.3064, 0.4209, 0.2912, 0.4179, 0.3026, 0.4041, 0.3296, 0.4131,\n",
      "         0.2862, 0.4224, 0.3020, 0.4008, 0.2780, 0.4215, 0.2948, 0.4035, 0.3033,\n",
      "         0.4141, 0.2945, 0.4035, 0.2948, 0.4272, 0.2955, 0.4026, 0.3017, 0.4156,\n",
      "         0.2968, 0.4120, 0.2846, 0.4278, 0.2916, 0.4089, 0.3063, 0.4176, 0.3097,\n",
      "         0.4217, 0.2957, 0.4021, 0.2976, 0.4109, 0.2953, 0.4317, 0.2893, 0.4187,\n",
      "         0.3058, 0.4094, 0.3239, 0.4009, 0.3058, 0.4184, 0.3028, 0.4299, 0.2824,\n",
      "         0.4140, 0.2997, 0.4159, 0.3083, 0.4165, 0.2952, 0.4072, 0.3037, 0.4095,\n",
      "         0.2915, 0.4003, 0.3092, 0.4220, 0.2841, 0.4131, 0.3028, 0.4181, 0.3248,\n",
      "         0.4063, 0.3057, 0.4185, 0.3051, 0.4120, 0.3038, 0.4178, 0.3029, 0.4030,\n",
      "         0.3102, 0.4224, 0.3010, 0.4090, 0.3161, 0.4003, 0.3105, 0.3987, 0.3050,\n",
      "         0.4251, 0.2822, 0.4085, 0.2948, 0.4207, 0.3094, 0.4098, 0.3000, 0.4196,\n",
      "         0.2983, 0.4094, 0.3056, 0.4288, 0.2993, 0.4025, 0.3155, 0.4121, 0.3257,\n",
      "         0.4061, 0.3032, 0.4208, 0.3068, 0.4068, 0.3024, 0.4195, 0.2964, 0.4072,\n",
      "         0.3021, 0.4162, 0.3036, 0.4062, 0.2885, 0.4198, 0.2789, 0.4027, 0.2924,\n",
      "         0.4255, 0.3006, 0.4112, 0.3075, 0.4166, 0.3255, 0.3990, 0.2999, 0.4227,\n",
      "         0.3018, 0.4208, 0.2989, 0.4077, 0.3192, 0.4174, 0.2918, 0.4137, 0.2911,\n",
      "         0.4197, 0.3071, 0.4092, 0.3107, 0.4099, 0.2858, 0.4142, 0.2977, 0.4129,\n",
      "         0.2948, 0.4153, 0.3563]], grad_fn=<SqueezeBackward1>)\n",
      "decoded.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "latent = torch.rand(3, 10 + 5 + 1)\n",
    "decoded = current_decoder(latent)\n",
    "print(f\"{decoded = }\")\n",
    "print(f\"{decoded.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalDecoder(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=50, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=50, out_features=100, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=100, out_features=960, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (unflatten): Unflatten(dim=1, unflattened_size=(32, 30))\n",
       "  (convnet): Sequential(\n",
       "    (0): ConvTranspose1d(32, 16, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): ConvTranspose1d(16, 8, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): ConvTranspose1d(8, 1, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formfactor_decoder = ConvolutionalDecoder(latent_dims=10 + 5 + 1, signal_dims=240)\n",
    "formfactor_decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded = tensor([[0.6500, 0.6566, 0.6798, 0.6840, 0.6584, 0.6638, 0.6894, 0.6669, 0.6447,\n",
      "         0.6617, 0.6758, 0.6618, 0.6412, 0.6610, 0.6857, 0.6701, 0.6433, 0.6655,\n",
      "         0.6616, 0.6546, 0.6497, 0.6661, 0.6858, 0.6751, 0.6530, 0.6641, 0.6800,\n",
      "         0.6695, 0.6500, 0.6615, 0.6831, 0.6685, 0.6417, 0.6533, 0.6770, 0.6748,\n",
      "         0.6447, 0.6562, 0.6867, 0.6658, 0.6411, 0.6637, 0.6749, 0.6686, 0.6442,\n",
      "         0.6599, 0.6766, 0.6672, 0.6522, 0.6700, 0.6746, 0.6551, 0.6403, 0.6611,\n",
      "         0.6813, 0.6686, 0.6406, 0.6532, 0.6556, 0.6616, 0.6530, 0.6700, 0.6848,\n",
      "         0.6671, 0.6483, 0.6608, 0.6796, 0.6731, 0.6431, 0.6562, 0.6801, 0.6658,\n",
      "         0.6559, 0.6712, 0.6696, 0.6542, 0.6465, 0.6717, 0.6847, 0.6700, 0.6547,\n",
      "         0.6740, 0.6843, 0.6648, 0.6535, 0.6711, 0.6843, 0.6687, 0.6459, 0.6653,\n",
      "         0.6750, 0.6567, 0.6416, 0.6573, 0.6799, 0.6757, 0.6545, 0.6678, 0.6889,\n",
      "         0.6782, 0.6441, 0.6481, 0.6731, 0.6704, 0.6478, 0.6607, 0.6784, 0.6680,\n",
      "         0.6560, 0.6756, 0.7016, 0.6726, 0.6523, 0.6714, 0.6555, 0.6525, 0.6421,\n",
      "         0.6553, 0.6829, 0.6764, 0.6551, 0.6671, 0.6822, 0.6763, 0.6567, 0.6680,\n",
      "         0.7006, 0.6706, 0.6479, 0.6615, 0.6694, 0.6661, 0.6427, 0.6577, 0.6911,\n",
      "         0.6701, 0.6443, 0.6715, 0.6626, 0.6522, 0.6508, 0.6729, 0.6817, 0.6647,\n",
      "         0.6466, 0.6640, 0.6719, 0.6655, 0.6515, 0.6629, 0.6907, 0.6786, 0.6486,\n",
      "         0.6631, 0.6788, 0.6616, 0.6442, 0.6605, 0.6826, 0.6714, 0.6474, 0.6637,\n",
      "         0.6660, 0.6563, 0.6427, 0.6643, 0.6870, 0.6732, 0.6557, 0.6740, 0.6684,\n",
      "         0.6536, 0.6366, 0.6539, 0.6724, 0.6687, 0.6445, 0.6698, 0.6824, 0.6564,\n",
      "         0.6460, 0.6703, 0.6811, 0.6746, 0.6524, 0.6669, 0.6879, 0.6761, 0.6432,\n",
      "         0.6518, 0.6790, 0.6640, 0.6425, 0.6639, 0.6745, 0.6694, 0.6601, 0.6767,\n",
      "         0.6954, 0.6696, 0.6523, 0.6693, 0.6750, 0.6611, 0.6446, 0.6638, 0.6783,\n",
      "         0.6643, 0.6475, 0.6739, 0.6829, 0.6603, 0.6556, 0.6835, 0.6946, 0.6693,\n",
      "         0.6552, 0.6695, 0.6772, 0.6717, 0.6517, 0.6635, 0.6909, 0.6755, 0.6540,\n",
      "         0.6653, 0.6861, 0.6757, 0.6449, 0.6556, 0.6835, 0.6683, 0.6491, 0.6620,\n",
      "         0.6750, 0.6685, 0.6500, 0.6652, 0.6783, 0.4761],\n",
      "        [0.6505, 0.6569, 0.6788, 0.6794, 0.6559, 0.6635, 0.6888, 0.6688, 0.6441,\n",
      "         0.6610, 0.6761, 0.6631, 0.6420, 0.6601, 0.6853, 0.6698, 0.6427, 0.6643,\n",
      "         0.6608, 0.6553, 0.6509, 0.6670, 0.6879, 0.6753, 0.6525, 0.6639, 0.6783,\n",
      "         0.6680, 0.6490, 0.6628, 0.6831, 0.6672, 0.6405, 0.6533, 0.6766, 0.6738,\n",
      "         0.6441, 0.6573, 0.6848, 0.6653, 0.6382, 0.6575, 0.6718, 0.6712, 0.6437,\n",
      "         0.6577, 0.6776, 0.6666, 0.6538, 0.6698, 0.6773, 0.6590, 0.6411, 0.6623,\n",
      "         0.6830, 0.6677, 0.6413, 0.6532, 0.6528, 0.6587, 0.6519, 0.6714, 0.6840,\n",
      "         0.6664, 0.6484, 0.6601, 0.6788, 0.6752, 0.6441, 0.6558, 0.6834, 0.6670,\n",
      "         0.6549, 0.6709, 0.6708, 0.6568, 0.6492, 0.6721, 0.6854, 0.6716, 0.6586,\n",
      "         0.6792, 0.6898, 0.6631, 0.6532, 0.6729, 0.6809, 0.6654, 0.6457, 0.6669,\n",
      "         0.6744, 0.6548, 0.6411, 0.6578, 0.6800, 0.6772, 0.6528, 0.6657, 0.6883,\n",
      "         0.6785, 0.6448, 0.6484, 0.6744, 0.6700, 0.6471, 0.6566, 0.6762, 0.6717,\n",
      "         0.6558, 0.6756, 0.7028, 0.6718, 0.6512, 0.6699, 0.6597, 0.6579, 0.6448,\n",
      "         0.6560, 0.6855, 0.6752, 0.6530, 0.6663, 0.6796, 0.6748, 0.6589, 0.6709,\n",
      "         0.7012, 0.6709, 0.6472, 0.6613, 0.6693, 0.6654, 0.6421, 0.6552, 0.6892,\n",
      "         0.6722, 0.6467, 0.6720, 0.6666, 0.6532, 0.6497, 0.6717, 0.6811, 0.6648,\n",
      "         0.6472, 0.6644, 0.6727, 0.6652, 0.6512, 0.6648, 0.6934, 0.6795, 0.6482,\n",
      "         0.6645, 0.6786, 0.6623, 0.6481, 0.6644, 0.6872, 0.6722, 0.6460, 0.6624,\n",
      "         0.6646, 0.6571, 0.6404, 0.6626, 0.6865, 0.6730, 0.6548, 0.6756, 0.6712,\n",
      "         0.6557, 0.6387, 0.6549, 0.6735, 0.6676, 0.6455, 0.6745, 0.6833, 0.6523,\n",
      "         0.6459, 0.6712, 0.6798, 0.6755, 0.6526, 0.6682, 0.6907, 0.6780, 0.6452,\n",
      "         0.6544, 0.6798, 0.6631, 0.6436, 0.6639, 0.6742, 0.6688, 0.6590, 0.6767,\n",
      "         0.6949, 0.6694, 0.6523, 0.6690, 0.6770, 0.6629, 0.6461, 0.6663, 0.6787,\n",
      "         0.6618, 0.6483, 0.6741, 0.6827, 0.6626, 0.6563, 0.6848, 0.6964, 0.6679,\n",
      "         0.6559, 0.6714, 0.6776, 0.6709, 0.6512, 0.6632, 0.6886, 0.6749, 0.6547,\n",
      "         0.6671, 0.6834, 0.6694, 0.6418, 0.6530, 0.6823, 0.6731, 0.6526, 0.6640,\n",
      "         0.6798, 0.6716, 0.6494, 0.6629, 0.6782, 0.4759],\n",
      "        [0.6476, 0.6544, 0.6825, 0.6869, 0.6576, 0.6616, 0.6931, 0.6715, 0.6458,\n",
      "         0.6627, 0.6761, 0.6638, 0.6434, 0.6631, 0.6901, 0.6704, 0.6420, 0.6656,\n",
      "         0.6643, 0.6575, 0.6516, 0.6673, 0.6830, 0.6703, 0.6505, 0.6651, 0.6810,\n",
      "         0.6697, 0.6501, 0.6627, 0.6793, 0.6677, 0.6404, 0.6501, 0.6751, 0.6774,\n",
      "         0.6493, 0.6610, 0.6895, 0.6633, 0.6380, 0.6643, 0.6764, 0.6699, 0.6490,\n",
      "         0.6651, 0.6795, 0.6653, 0.6495, 0.6670, 0.6716, 0.6561, 0.6416, 0.6596,\n",
      "         0.6811, 0.6719, 0.6426, 0.6574, 0.6641, 0.6646, 0.6524, 0.6682, 0.6882,\n",
      "         0.6675, 0.6472, 0.6588, 0.6771, 0.6744, 0.6478, 0.6639, 0.6876, 0.6676,\n",
      "         0.6565, 0.6707, 0.6708, 0.6566, 0.6478, 0.6681, 0.6840, 0.6724, 0.6566,\n",
      "         0.6729, 0.6880, 0.6685, 0.6537, 0.6680, 0.6828, 0.6663, 0.6457, 0.6652,\n",
      "         0.6742, 0.6576, 0.6443, 0.6634, 0.6830, 0.6721, 0.6494, 0.6650, 0.6841,\n",
      "         0.6752, 0.6408, 0.6443, 0.6748, 0.6740, 0.6472, 0.6575, 0.6779, 0.6730,\n",
      "         0.6594, 0.6754, 0.7038, 0.6718, 0.6514, 0.6706, 0.6619, 0.6545, 0.6439,\n",
      "         0.6638, 0.6836, 0.6694, 0.6511, 0.6663, 0.6797, 0.6746, 0.6549, 0.6695,\n",
      "         0.7006, 0.6732, 0.6510, 0.6643, 0.6695, 0.6645, 0.6445, 0.6592, 0.6922,\n",
      "         0.6705, 0.6394, 0.6623, 0.6627, 0.6588, 0.6500, 0.6689, 0.6833, 0.6665,\n",
      "         0.6478, 0.6613, 0.6706, 0.6666, 0.6499, 0.6620, 0.6883, 0.6752, 0.6488,\n",
      "         0.6617, 0.6796, 0.6669, 0.6432, 0.6544, 0.6817, 0.6725, 0.6494, 0.6605,\n",
      "         0.6687, 0.6616, 0.6469, 0.6667, 0.6883, 0.6713, 0.6549, 0.6713, 0.6709,\n",
      "         0.6589, 0.6401, 0.6533, 0.6747, 0.6715, 0.6455, 0.6716, 0.6848, 0.6539,\n",
      "         0.6485, 0.6747, 0.6829, 0.6755, 0.6515, 0.6662, 0.6833, 0.6709, 0.6402,\n",
      "         0.6496, 0.6781, 0.6658, 0.6442, 0.6641, 0.6748, 0.6716, 0.6609, 0.6755,\n",
      "         0.6951, 0.6688, 0.6520, 0.6705, 0.6754, 0.6586, 0.6498, 0.6715, 0.6772,\n",
      "         0.6631, 0.6491, 0.6774, 0.6831, 0.6529, 0.6522, 0.6822, 0.6878, 0.6691,\n",
      "         0.6526, 0.6654, 0.6820, 0.6767, 0.6493, 0.6588, 0.6899, 0.6750, 0.6506,\n",
      "         0.6626, 0.6806, 0.6725, 0.6453, 0.6584, 0.6842, 0.6674, 0.6473, 0.6612,\n",
      "         0.6750, 0.6711, 0.6507, 0.6652, 0.6782, 0.4753]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "decoded.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "latent = torch.rand(3, 10 + 5 + 1)\n",
    "decoded = formfactor_decoder(latent)\n",
    "print(f\"{decoded = }\")\n",
    "print(f\"{decoded.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (formfactor_encoder): ConvolutionalEncoder(\n",
       "    (convnet): Sequential(\n",
       "      (0): Conv1d(1, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=960, out_features=100, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (current_decoder): ConvolutionalDecoder(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=50, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=50, out_features=100, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=100, out_features=1216, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (unflatten): Unflatten(dim=1, unflattened_size=(32, 38))\n",
       "    (convnet): Sequential(\n",
       "      (0): ConvTranspose1d(32, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): ConvTranspose1d(16, 8, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): ConvTranspose1d(8, 1, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "      (5): ReLU()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = Generator()\n",
    "generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.parameters().__next__().requires_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_profile.size() = torch.Size([3, 300])\n",
      "current_profile.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "formfactor = torch.rand(3, 240)\n",
    "rf_settings = torch.rand(3, 5)\n",
    "bunch_length = torch.rand(3, 1)\n",
    "\n",
    "current_profile = generator(formfactor, rf_settings, bunch_length)\n",
    "print(f\"{current_profile.size() = }\")\n",
    "print(f\"{current_profile.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Critic(\n",
       "  (formfactor_encoder): ConvolutionalEncoder(\n",
       "    (convnet): Sequential(\n",
       "      (0): Conv1d(1, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=960, out_features=100, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (current_encoder): ConvolutionalEncoder(\n",
       "    (convnet): Sequential(\n",
       "      (0): Conv1d(1, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=1216, out_features=100, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=26, out_features=50, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=50, out_features=20, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=20, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic = Critic()\n",
    "critic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "critique = tensor([[-0.0524],\n",
      "        [-0.0548],\n",
      "        [-0.0673]], grad_fn=<AddmmBackward0>)\n",
      "critique.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "critique = critic(current_profile, formfactor, rf_settings, bunch_length)\n",
    "print(f\"{critique = }\")\n",
    "print(f\"{critique.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<train_gan.EuXFELCurrentDataset at 0x2af237310>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = EuXFELCurrentDataset(normalize=True)\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(formfactor, rf_settings, bunch_length), current_profile = dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5686,  0.7723,  1.0779,  0.6725,  0.4086,  0.7040,  0.5354,  0.4655,\n",
       "         0.3015,  0.7461,  0.6887,  0.3759,  0.4386,  0.4940,  0.5174,  0.7427,\n",
       "         0.5371,  0.4569,  0.4125,  0.7526,  0.5118,  0.5952,  0.3537,  0.6484,\n",
       "         0.6500,  0.5328,  0.5734,  0.4914,  0.6267,  0.4590,  0.4502,  0.7758,\n",
       "         0.7688,  0.6264,  0.5553,  0.6135,  0.6125,  0.5770,  0.5955,  0.5749,\n",
       "         0.5826,  0.6356,  0.6191,  0.5773,  0.5847,  0.6125,  0.5815,  0.5982,\n",
       "         0.5877,  0.5858,  0.6251,  0.5709,  0.5883,  0.5329,  0.5751,  0.5578,\n",
       "         0.5513,  0.5446,  0.5241,  0.4902,  0.5763,  0.5922,  0.4785,  0.5050,\n",
       "         0.3155,  0.4155,  0.3747,  0.3794,  0.3606,  0.3266,  0.2784,  0.3489,\n",
       "         0.3376,  0.3628,  0.2933,  0.1993,  0.2270,  0.2109,  0.2252,  0.1737,\n",
       "         0.1151,  0.0970,  0.0518,  0.0090, -0.0781, -0.1075, -0.1452, -0.2126,\n",
       "        -0.2592, -0.2709, -0.1551, -0.9425, -0.0910, -0.2910, -0.6669, -0.1924,\n",
       "        -0.3548, -0.5469, -0.2502, -0.4975, -0.2743, -0.3697, -0.3747, -0.5254,\n",
       "        -0.5297, -0.5032, -0.4027, -0.4687, -0.4581, -0.3169, -0.3431, -0.3145,\n",
       "        -0.2775, -0.2540, -0.2224, -0.1745, -0.1663, -0.1338, -0.1523, -0.1889,\n",
       "        -0.4094, -0.3634,  0.0669, -0.0310, -0.2066, -0.1891, -0.1944, -0.1425,\n",
       "        -0.1700, -0.2125, -0.2280, -0.3532, -0.2814, -0.2878, -0.3218, -0.9211,\n",
       "        -0.3848, -0.3730, -0.3972, -0.3910, -0.3349, -0.3087, -0.2746, -0.1905,\n",
       "        -0.1649, -0.1437, -0.1224, -0.1392, -0.1981, -0.1923, -0.0120, -0.2098,\n",
       "        -0.1594, -0.4986, -0.1397, -0.2893, -0.3135, -0.3504, -0.3078, -0.4918,\n",
       "        -0.6969, -0.4080, -0.3166, -0.5033, -0.7600, -0.1741, -0.1682, -0.2129,\n",
       "        -0.1348, -0.0662, -0.1119, -0.1195, -0.2029, -0.2510, -0.3042, -0.3752,\n",
       "        -0.3280, -0.2074, -0.1548, -0.1663,  0.2302, -0.9348, -0.1626, -0.2796,\n",
       "        -0.4393, -0.2753, -0.7792, -0.3955, -0.3331,  0.0269, -0.2896, -0.1551,\n",
       "        -0.1981, -0.1539, -0.1558, -0.0789, -0.2351, -0.6631, -0.3914, -0.3251,\n",
       "        -0.1165, -0.1025, -0.1352, -0.3292, -0.3340, -0.1067, -0.0916, -0.1256,\n",
       "        -0.1897, -0.9019,  0.4373, -0.8310, -0.7108,  0.2376,  0.3572, -0.6436,\n",
       "        -0.2060, -0.0540,  0.0652, -0.0466, -0.5864, -0.1534, -0.2520, -0.0674,\n",
       "        -0.0511,  0.1207, -0.6316, -0.8025, -0.3685, -1.2056,  0.1355, -0.7147,\n",
       "        -0.0946, -0.0803, -0.7306,  0.2568,  0.0189, -1.0840, -1.2624, -1.1635])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formfactor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0250,  0.6563, -0.4842, -0.3788,  1.2869])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6858])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bunch_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.4061,  1.2965,  1.2059,  1.1369,  1.0940,  1.0753,  1.0729,  1.0814,\n",
       "         1.0948,  1.1041,  1.1080,  1.1046,  1.0936,  1.0738,  1.0494,  1.0220,\n",
       "         0.9934,  0.9643,  0.9370,  0.9125,  0.8915,  0.8740,  0.8595,  0.8470,\n",
       "         0.8360,  0.8264,  0.8186,  0.8138,  0.8127,  0.8161,  0.8237,  0.8344,\n",
       "         0.8471,  0.8604,  0.8733,  0.8852,  0.8958,  0.9049,  0.9122,  0.9176,\n",
       "         0.9211,  0.9231,  0.9238,  0.9236,  0.9224,  0.9199,  0.9148,  0.9060,\n",
       "         0.8928,  0.8749,  0.8543,  0.8332,  0.8142,  0.7988,  0.7874,  0.7787,\n",
       "         0.7711,  0.7625,  0.7515,  0.7370,  0.7187,  0.6966,  0.6715,  0.6449,\n",
       "         0.6183,  0.5929,  0.5700,  0.5502,  0.5336,  0.5199,  0.5086,  0.4988,\n",
       "         0.4902,  0.4821,  0.4734,  0.4635,  0.4518,  0.4380,  0.4223,  0.4053,\n",
       "         0.3874,  0.3691,  0.3507,  0.3328,  0.3160,  0.3007,  0.2868,  0.2730,\n",
       "         0.2580,  0.2406,  0.2204,  0.1986,  0.1767,  0.1562,  0.1389,  0.1250,\n",
       "         0.1143,  0.1059,  0.0984,  0.0899,  0.0792,  0.0657,  0.0490,  0.0300,\n",
       "         0.0095, -0.0116, -0.0322, -0.0516, -0.0691, -0.0841, -0.0960, -0.1050,\n",
       "        -0.1115, -0.1163, -0.1200, -0.1234, -0.1268, -0.1304, -0.1342, -0.1384,\n",
       "        -0.1433, -0.1491, -0.1562, -0.1642, -0.1727, -0.1810, -0.1881, -0.1936,\n",
       "        -0.1973, -0.1995, -0.2007, -0.2017, -0.2030, -0.2051, -0.2082, -0.2122,\n",
       "        -0.2168, -0.2219, -0.2273, -0.2333, -0.2398, -0.2471, -0.2554, -0.2647,\n",
       "        -0.2746, -0.2849, -0.2950, -0.3041, -0.3121, -0.3185, -0.3233, -0.3268,\n",
       "        -0.3293, -0.3314, -0.3333, -0.3356, -0.3381, -0.3409, -0.3440, -0.3474,\n",
       "        -0.3507, -0.3540, -0.3569, -0.3594, -0.3613, -0.3623, -0.3627, -0.3624,\n",
       "        -0.3615, -0.3599, -0.3575, -0.3542, -0.3495, -0.3431, -0.3346, -0.3230,\n",
       "        -0.3075, -0.2870, -0.2604, -0.2262, -0.1843, -0.1351, -0.0806, -0.0235,\n",
       "         0.0337,  0.0892,  0.1420,  0.1919,  0.2393,  0.2841,  0.3260,  0.3651,\n",
       "         0.4018,  0.4371,  0.4721,  0.5082,  0.5461,  0.5862,  0.6281,  0.6712,\n",
       "         0.7145,  0.7574,  0.7991,  0.8390,  0.8765,  0.9114,  0.9432,  0.9722,\n",
       "         0.9987,  1.0237,  1.0477,  1.0716,  1.0958,  1.1210,  1.1467,  1.1738,\n",
       "         1.2022,  1.2324,  1.2649,  1.3007,  1.3405,  1.3852,  1.4359,  1.4943,\n",
       "         1.5619,  1.6391,  1.7256,  1.8197,  1.9163,  2.0087,  2.0879,  2.1392,\n",
       "         2.1492,  2.1069,  2.0029,  1.8258,  1.5832,  1.2915,  0.9701,  0.6449,\n",
       "         0.3415,  0.0754, -0.1437, -0.3085, -0.4254, -0.5058, -0.5574, -0.5862,\n",
       "        -0.6001, -0.6054, -0.6052, -0.6019, -0.5967, -0.5906, -0.5839, -0.5769,\n",
       "        -0.5696, -0.5621, -0.5545, -0.5470, -0.5397, -0.5326, -0.5259, -0.5193,\n",
       "        -0.5121, -0.5036, -0.4935, -0.4812, -0.4670, -0.4516, -0.4358, -0.4197,\n",
       "        -0.4037, -0.3874, -0.3706, -0.3530, -0.3348, -0.3165, -0.2983, -0.2808,\n",
       "        -0.2641, -0.2486, -0.2344, -0.2214, -0.2089, -0.1968, -0.1850, -0.1738,\n",
       "        -0.1638, -0.1555, -0.1493, -0.1452, -0.1424, -0.1400, -0.1373, -0.1339,\n",
       "        -0.1302, -0.1279, -0.1281, -0.1239])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<train_gan.EuXFELCurrentDataModule at 0x2af237490>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module = EuXFELCurrentDataModule(batch_size=64, normalize=True)\n",
    "data_module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.setup(stage=\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2af2376d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = data_module.train_dataloader()\n",
    "data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spectral-vd-euxfel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
