{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from train_gan import (\n",
    "    Critic,\n",
    "    EuXFELCurrentDataModule,\n",
    "    EuXFELCurrentDataset,\n",
    "    Generator,\n",
    "    ConvolutionalDecoder,\n",
    "    ConvolutionalEncoder,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalEncoder(\n",
       "  (convnet): Sequential(\n",
       "    (0): Conv1d(1, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=960, out_features=100, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formfactor_encoder = ConvolutionalEncoder(signal_dims=240, latent_dims=10)\n",
    "formfactor_encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded = tensor([[-0.0639,  0.0910, -0.0980, -0.0625, -0.0759, -0.0094,  0.0636, -0.1240,\n",
      "         -0.0454,  0.0487],\n",
      "        [-0.0655,  0.0900, -0.0978, -0.0640, -0.0763, -0.0097,  0.0666, -0.1220,\n",
      "         -0.0442,  0.0495],\n",
      "        [-0.0644,  0.0895, -0.0972, -0.0617, -0.0767, -0.0083,  0.0657, -0.1216,\n",
      "         -0.0453,  0.0498]], grad_fn=<AddmmBackward0>)\n",
      "encoded.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "formfactor = torch.rand(3, 240)\n",
    "encoded = formfactor_encoder(formfactor)\n",
    "print(f\"{encoded = }\")\n",
    "print(f\"{encoded.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalEncoder(\n",
       "  (convnet): Sequential(\n",
       "    (0): Conv1d(1, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=1216, out_features=100, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_encoder = ConvolutionalEncoder(signal_dims=300, latent_dims=10)\n",
    "current_encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded = tensor([[ 0.0496, -0.0315,  0.0538,  0.0646,  0.1436,  0.1433,  0.1666,  0.0769,\n",
      "         -0.1351,  0.1059],\n",
      "        [ 0.0520, -0.0311,  0.0539,  0.0665,  0.1418,  0.1418,  0.1666,  0.0758,\n",
      "         -0.1379,  0.1068],\n",
      "        [ 0.0514, -0.0323,  0.0541,  0.0645,  0.1425,  0.1420,  0.1664,  0.0743,\n",
      "         -0.1361,  0.1067]], grad_fn=<AddmmBackward0>)\n",
      "encoded.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "current_profile = torch.rand(3, 300)\n",
    "encoded = current_encoder(current_profile)\n",
    "print(f\"{encoded = }\")\n",
    "print(f\"{encoded.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalDecoder(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=50, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=50, out_features=100, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=100, out_features=1216, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (unflatten): Unflatten(dim=1, unflattened_size=(32, 38))\n",
       "  (convnet): Sequential(\n",
       "    (0): ConvTranspose1d(32, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): ConvTranspose1d(16, 8, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): ConvTranspose1d(8, 1, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_decoder = ConvolutionalDecoder(latent_dims=10 + 5 + 1, signal_dims=300)\n",
    "current_decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_decoder.parameters().__next__().requires_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded = tensor([[0.4901, 0.5386, 0.5056, 0.5496, 0.5053, 0.5436, 0.5077, 0.5483, 0.4996,\n",
      "         0.5443, 0.4973, 0.5507, 0.4987, 0.5418, 0.4984, 0.5412, 0.4960, 0.5370,\n",
      "         0.4984, 0.5440, 0.4938, 0.5376, 0.5007, 0.5494, 0.4918, 0.5414, 0.4980,\n",
      "         0.5513, 0.4957, 0.5401, 0.5017, 0.5492, 0.4946, 0.5358, 0.5051, 0.5509,\n",
      "         0.5034, 0.5364, 0.5002, 0.5446, 0.4944, 0.5360, 0.4972, 0.5496, 0.4885,\n",
      "         0.5240, 0.5034, 0.5447, 0.4954, 0.5389, 0.5054, 0.5434, 0.4990, 0.5363,\n",
      "         0.5025, 0.5404, 0.5058, 0.5441, 0.4982, 0.5571, 0.4864, 0.5300, 0.5043,\n",
      "         0.5475, 0.5003, 0.5396, 0.4953, 0.5387, 0.4833, 0.5311, 0.5021, 0.5479,\n",
      "         0.4923, 0.5338, 0.5000, 0.5448, 0.4907, 0.5343, 0.5140, 0.5462, 0.4996,\n",
      "         0.5387, 0.5063, 0.5496, 0.5027, 0.5333, 0.5078, 0.5531, 0.4980, 0.5320,\n",
      "         0.5071, 0.5538, 0.4945, 0.5338, 0.5088, 0.5563, 0.4963, 0.5424, 0.5006,\n",
      "         0.5466, 0.4983, 0.5451, 0.4974, 0.5478, 0.4952, 0.5452, 0.4977, 0.5469,\n",
      "         0.4956, 0.5392, 0.5015, 0.5404, 0.5034, 0.5407, 0.5129, 0.5516, 0.5059,\n",
      "         0.5444, 0.5008, 0.5510, 0.4992, 0.5439, 0.5028, 0.5556, 0.5008, 0.5388,\n",
      "         0.4908, 0.5449, 0.4874, 0.5360, 0.5107, 0.5498, 0.5071, 0.5381, 0.5097,\n",
      "         0.5517, 0.4948, 0.5323, 0.5044, 0.5510, 0.4965, 0.5400, 0.5008, 0.5461,\n",
      "         0.4964, 0.5366, 0.4987, 0.5418, 0.4889, 0.5366, 0.5089, 0.5547, 0.4949,\n",
      "         0.5484, 0.5009, 0.5434, 0.4960, 0.5428, 0.5017, 0.5533, 0.4956, 0.5459,\n",
      "         0.5001, 0.5512, 0.4982, 0.5447, 0.4877, 0.5401, 0.4899, 0.5377, 0.5047,\n",
      "         0.5391, 0.4950, 0.5373, 0.5069, 0.5576, 0.4937, 0.5391, 0.5057, 0.5527,\n",
      "         0.4973, 0.5369, 0.5012, 0.5412, 0.4930, 0.5333, 0.4990, 0.5408, 0.4953,\n",
      "         0.5420, 0.5012, 0.5480, 0.5042, 0.5424, 0.5084, 0.5545, 0.5038, 0.5374,\n",
      "         0.5018, 0.5438, 0.4941, 0.5361, 0.4986, 0.5464, 0.4926, 0.5381, 0.4994,\n",
      "         0.5514, 0.4930, 0.5436, 0.5055, 0.5528, 0.4955, 0.5483, 0.5031, 0.5479,\n",
      "         0.5002, 0.5540, 0.5057, 0.5459, 0.5028, 0.5451, 0.4967, 0.5464, 0.4969,\n",
      "         0.5390, 0.5044, 0.5508, 0.4978, 0.5439, 0.5013, 0.5474, 0.4964, 0.5496,\n",
      "         0.4973, 0.5468, 0.4893, 0.5404, 0.5029, 0.5464, 0.4978, 0.5469, 0.4971,\n",
      "         0.5468, 0.4911, 0.5345, 0.5045, 0.5525, 0.4983, 0.5328, 0.5110, 0.5512,\n",
      "         0.4949, 0.5351, 0.5095, 0.5451, 0.4968, 0.5434, 0.5038, 0.5550, 0.4973,\n",
      "         0.5434, 0.4972, 0.5511, 0.5016, 0.5414, 0.5105, 0.5541, 0.4998, 0.5471,\n",
      "         0.5008, 0.5551, 0.4955, 0.5478, 0.4977, 0.5474, 0.4961, 0.5344, 0.5007,\n",
      "         0.5508, 0.4936, 0.5310, 0.5026, 0.5459, 0.5127, 0.5454, 0.5075, 0.5607,\n",
      "         0.4872, 0.5294, 0.4982, 0.5509, 0.4957, 0.5361, 0.5000, 0.5556, 0.4911,\n",
      "         0.5420, 0.5026, 0.5158],\n",
      "        [0.4905, 0.5354, 0.5056, 0.5498, 0.5041, 0.5401, 0.5103, 0.5504, 0.4986,\n",
      "         0.5400, 0.5007, 0.5510, 0.5048, 0.5437, 0.5017, 0.5421, 0.4989, 0.5425,\n",
      "         0.4980, 0.5470, 0.4960, 0.5427, 0.4957, 0.5470, 0.4924, 0.5408, 0.4981,\n",
      "         0.5480, 0.4947, 0.5373, 0.5005, 0.5472, 0.4925, 0.5392, 0.5071, 0.5513,\n",
      "         0.5003, 0.5383, 0.4961, 0.5399, 0.4967, 0.5390, 0.4984, 0.5514, 0.4904,\n",
      "         0.5293, 0.5042, 0.5423, 0.4948, 0.5440, 0.5040, 0.5452, 0.5023, 0.5413,\n",
      "         0.4990, 0.5377, 0.5037, 0.5411, 0.4974, 0.5568, 0.4862, 0.5314, 0.5080,\n",
      "         0.5485, 0.4999, 0.5404, 0.4976, 0.5418, 0.4875, 0.5343, 0.5012, 0.5464,\n",
      "         0.4946, 0.5379, 0.4982, 0.5473, 0.4938, 0.5393, 0.5118, 0.5471, 0.4992,\n",
      "         0.5396, 0.5069, 0.5479, 0.5040, 0.5385, 0.5082, 0.5544, 0.4952, 0.5313,\n",
      "         0.5068, 0.5522, 0.4932, 0.5358, 0.5081, 0.5517, 0.4971, 0.5431, 0.5013,\n",
      "         0.5477, 0.4975, 0.5450, 0.4994, 0.5516, 0.4957, 0.5451, 0.4977, 0.5489,\n",
      "         0.4951, 0.5418, 0.5030, 0.5402, 0.5043, 0.5421, 0.5095, 0.5498, 0.5017,\n",
      "         0.5441, 0.5005, 0.5525, 0.4999, 0.5454, 0.5039, 0.5543, 0.5011, 0.5406,\n",
      "         0.4920, 0.5466, 0.4887, 0.5385, 0.5052, 0.5466, 0.5004, 0.5367, 0.5057,\n",
      "         0.5515, 0.4947, 0.5348, 0.5042, 0.5503, 0.4970, 0.5375, 0.4997, 0.5445,\n",
      "         0.4952, 0.5327, 0.5026, 0.5420, 0.4888, 0.5361, 0.5101, 0.5559, 0.4948,\n",
      "         0.5506, 0.5019, 0.5430, 0.4980, 0.5422, 0.5012, 0.5538, 0.4947, 0.5432,\n",
      "         0.5008, 0.5511, 0.4984, 0.5430, 0.4887, 0.5389, 0.4860, 0.5357, 0.5086,\n",
      "         0.5388, 0.4963, 0.5373, 0.5067, 0.5583, 0.4944, 0.5387, 0.5025, 0.5529,\n",
      "         0.4953, 0.5367, 0.4990, 0.5399, 0.4918, 0.5317, 0.5017, 0.5412, 0.4953,\n",
      "         0.5440, 0.5045, 0.5487, 0.5046, 0.5483, 0.5066, 0.5538, 0.5025, 0.5367,\n",
      "         0.5006, 0.5432, 0.4946, 0.5356, 0.4991, 0.5460, 0.4931, 0.5378, 0.5011,\n",
      "         0.5524, 0.4923, 0.5447, 0.5072, 0.5530, 0.4968, 0.5488, 0.5022, 0.5474,\n",
      "         0.4995, 0.5505, 0.5045, 0.5456, 0.5009, 0.5452, 0.4992, 0.5497, 0.4980,\n",
      "         0.5383, 0.5006, 0.5484, 0.4967, 0.5425, 0.5015, 0.5447, 0.4965, 0.5513,\n",
      "         0.4993, 0.5465, 0.4957, 0.5414, 0.5008, 0.5417, 0.4954, 0.5457, 0.4967,\n",
      "         0.5453, 0.4922, 0.5360, 0.5068, 0.5569, 0.5013, 0.5302, 0.5116, 0.5538,\n",
      "         0.4936, 0.5293, 0.5126, 0.5509, 0.4954, 0.5437, 0.5005, 0.5542, 0.5006,\n",
      "         0.5422, 0.4927, 0.5467, 0.5004, 0.5422, 0.5104, 0.5520, 0.5003, 0.5436,\n",
      "         0.5015, 0.5541, 0.4935, 0.5438, 0.4983, 0.5475, 0.4953, 0.5363, 0.5027,\n",
      "         0.5482, 0.4979, 0.5325, 0.5049, 0.5482, 0.5095, 0.5424, 0.5097, 0.5627,\n",
      "         0.4864, 0.5295, 0.4966, 0.5500, 0.4940, 0.5336, 0.4984, 0.5552, 0.4903,\n",
      "         0.5384, 0.5044, 0.5175],\n",
      "        [0.4907, 0.5388, 0.5072, 0.5495, 0.5078, 0.5444, 0.5091, 0.5495, 0.4994,\n",
      "         0.5444, 0.4970, 0.5507, 0.4984, 0.5430, 0.5004, 0.5430, 0.4974, 0.5397,\n",
      "         0.4991, 0.5462, 0.4954, 0.5422, 0.4972, 0.5495, 0.4924, 0.5418, 0.5000,\n",
      "         0.5504, 0.4956, 0.5390, 0.5014, 0.5483, 0.4949, 0.5391, 0.5073, 0.5514,\n",
      "         0.5035, 0.5403, 0.4956, 0.5418, 0.4948, 0.5338, 0.4981, 0.5489, 0.4884,\n",
      "         0.5250, 0.5049, 0.5455, 0.4961, 0.5431, 0.5067, 0.5464, 0.5030, 0.5444,\n",
      "         0.4992, 0.5398, 0.5035, 0.5394, 0.4990, 0.5507, 0.4895, 0.5364, 0.5066,\n",
      "         0.5478, 0.5011, 0.5401, 0.4959, 0.5394, 0.4880, 0.5325, 0.5020, 0.5475,\n",
      "         0.4931, 0.5342, 0.4982, 0.5462, 0.4929, 0.5366, 0.5123, 0.5475, 0.4989,\n",
      "         0.5406, 0.5102, 0.5496, 0.5029, 0.5397, 0.5075, 0.5556, 0.4983, 0.5361,\n",
      "         0.5107, 0.5544, 0.4967, 0.5393, 0.5076, 0.5539, 0.4956, 0.5444, 0.5031,\n",
      "         0.5463, 0.4992, 0.5453, 0.4995, 0.5526, 0.4945, 0.5442, 0.4974, 0.5468,\n",
      "         0.4945, 0.5389, 0.5018, 0.5401, 0.5043, 0.5395, 0.5108, 0.5507, 0.5029,\n",
      "         0.5447, 0.5006, 0.5518, 0.4991, 0.5441, 0.4989, 0.5560, 0.4972, 0.5404,\n",
      "         0.4922, 0.5427, 0.4900, 0.5418, 0.5102, 0.5480, 0.5041, 0.5384, 0.5056,\n",
      "         0.5525, 0.4927, 0.5328, 0.5042, 0.5497, 0.4966, 0.5402, 0.4999, 0.5450,\n",
      "         0.4967, 0.5356, 0.5031, 0.5433, 0.4909, 0.5377, 0.5091, 0.5551, 0.4949,\n",
      "         0.5496, 0.5004, 0.5422, 0.4974, 0.5440, 0.5003, 0.5522, 0.4957, 0.5441,\n",
      "         0.4993, 0.5526, 0.4964, 0.5406, 0.4868, 0.5349, 0.4904, 0.5376, 0.5044,\n",
      "         0.5406, 0.4952, 0.5365, 0.5066, 0.5576, 0.4936, 0.5394, 0.5036, 0.5522,\n",
      "         0.4962, 0.5368, 0.5003, 0.5402, 0.4928, 0.5314, 0.4992, 0.5399, 0.4973,\n",
      "         0.5441, 0.4977, 0.5466, 0.5047, 0.5451, 0.5103, 0.5530, 0.5011, 0.5385,\n",
      "         0.5022, 0.5439, 0.4938, 0.5356, 0.4982, 0.5459, 0.4929, 0.5384, 0.4990,\n",
      "         0.5508, 0.4927, 0.5442, 0.5058, 0.5541, 0.4957, 0.5493, 0.5013, 0.5466,\n",
      "         0.4997, 0.5543, 0.5060, 0.5445, 0.5033, 0.5461, 0.4981, 0.5477, 0.4991,\n",
      "         0.5371, 0.5015, 0.5511, 0.4954, 0.5417, 0.5024, 0.5466, 0.4971, 0.5506,\n",
      "         0.4990, 0.5475, 0.4948, 0.5407, 0.5017, 0.5415, 0.4967, 0.5475, 0.4951,\n",
      "         0.5476, 0.4910, 0.5373, 0.5019, 0.5511, 0.4979, 0.5339, 0.5146, 0.5508,\n",
      "         0.4953, 0.5337, 0.5116, 0.5486, 0.4954, 0.5434, 0.5002, 0.5539, 0.4993,\n",
      "         0.5423, 0.4941, 0.5491, 0.5004, 0.5419, 0.5102, 0.5528, 0.5001, 0.5474,\n",
      "         0.5015, 0.5497, 0.4966, 0.5479, 0.4980, 0.5482, 0.4962, 0.5370, 0.5007,\n",
      "         0.5514, 0.4963, 0.5335, 0.5008, 0.5466, 0.5119, 0.5452, 0.5072, 0.5613,\n",
      "         0.4877, 0.5317, 0.4974, 0.5503, 0.4949, 0.5378, 0.4984, 0.5541, 0.4907,\n",
      "         0.5416, 0.5030, 0.5162]], grad_fn=<SqueezeBackward1>)\n",
      "decoded.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "latent = torch.rand(3, 10 + 5 + 1)\n",
    "decoded = current_decoder(latent)\n",
    "print(f\"{decoded = }\")\n",
    "print(f\"{decoded.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalDecoder(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=50, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=50, out_features=100, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=100, out_features=960, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (unflatten): Unflatten(dim=1, unflattened_size=(32, 30))\n",
       "  (convnet): Sequential(\n",
       "    (0): ConvTranspose1d(32, 16, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): ConvTranspose1d(16, 8, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): ConvTranspose1d(8, 1, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formfactor_decoder = ConvolutionalDecoder(latent_dims=10 + 5 + 1, signal_dims=240)\n",
    "formfactor_decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded = tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "decoded.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "latent = torch.rand(3, 10 + 5 + 1)\n",
    "decoded = formfactor_decoder(latent)\n",
    "print(f\"{decoded = }\")\n",
    "print(f\"{decoded.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (formfactor_encoder): ConvolutionalEncoder(\n",
       "    (convnet): Sequential(\n",
       "      (0): Conv1d(1, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=960, out_features=100, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (scalar_spectral_combine_mlp): Sequential(\n",
       "    (0): Linear(in_features=15, out_features=50, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=50, out_features=20, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=20, out_features=10, bias=True)\n",
       "  )\n",
       "  (current_decoder): ConvolutionalDecoder(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=50, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=50, out_features=100, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=100, out_features=1216, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (unflatten): Unflatten(dim=1, unflattened_size=(32, 38))\n",
       "    (convnet): Sequential(\n",
       "      (0): ConvTranspose1d(32, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): ConvTranspose1d(16, 8, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): ConvTranspose1d(8, 1, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "      (5): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (bunch_length_decoder): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=20, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=20, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = Generator()\n",
    "generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.parameters().__next__().requires_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_profile.size() = torch.Size([3, 300])\n",
      "current_profile.requires_grad = True\n",
      "bunch_length.size() = torch.Size([3, 1])\n",
      "bunch_length.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "rf_settings = torch.rand(3, 5)\n",
    "formfactor = torch.rand(3, 240)\n",
    "\n",
    "current_profile, bunch_length = generator(rf_settings, formfactor)\n",
    "print(f\"{current_profile.size() = }\")\n",
    "print(f\"{current_profile.requires_grad = }\")\n",
    "print(f\"{bunch_length.size() = }\")\n",
    "print(f\"{bunch_length.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Critic(\n",
       "  (formfactor_encoder): ConvolutionalEncoder(\n",
       "    (convnet): Sequential(\n",
       "      (0): Conv1d(1, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=960, out_features=100, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (current_encoder): ConvolutionalEncoder(\n",
       "    (convnet): Sequential(\n",
       "      (0): Conv1d(1, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=1216, out_features=100, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=26, out_features=50, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=50, out_features=20, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=20, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic = Critic()\n",
    "critic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "critique = tensor([[-0.0552],\n",
      "        [-0.0695],\n",
      "        [-0.0499]], grad_fn=<AddmmBackward0>)\n",
      "critique.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "critique = critic(rf_settings, formfactor, current_profile, bunch_length)\n",
    "print(f\"{critique = }\")\n",
    "print(f\"{critique.requires_grad = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<train_gan.EuXFELCurrentDataset at 0x2a9df0490>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = EuXFELCurrentDataset(normalize=True)\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25600"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(rf_settings, formfactor), (current_profile, bunch_length) = dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.7084,  0.3383, -1.2126,  0.4945,  0.6809,  0.2575,  0.4530,  0.4780,\n",
       "         0.5395,  0.5633,  0.7271,  0.3564,  0.5511,  0.8542,  0.6780,  0.3046,\n",
       "         0.7898,  0.7712,  0.8822,  0.7930,  0.9108,  0.8205,  0.8450,  0.8070,\n",
       "         0.8214,  0.8884,  0.8506,  0.9235,  0.8703,  0.8487,  0.8226,  0.8884,\n",
       "         1.0721,  0.5000,  0.9647,  0.9065,  0.8927,  0.9351,  0.9809,  0.9506,\n",
       "         0.9551,  1.0143,  1.0424,  1.0778,  1.0284,  1.0647,  1.0416,  1.1065,\n",
       "         1.1268,  1.1140,  1.1473,  1.1615,  1.1791,  1.2142,  1.2281,  1.2646,\n",
       "         1.3042,  1.3204,  1.3393,  1.3756,  1.3056,  1.3127,  1.2665,  1.3649,\n",
       "         1.3368,  1.4493,  1.4306,  1.4408,  1.4224,  1.3839,  1.4319,  1.4403,\n",
       "         1.4972,  1.5371,  1.5012,  1.5207,  1.5666,  1.5677,  1.6014,  1.6086,\n",
       "         1.6435,  1.6570,  1.6868,  1.7112,  1.7433,  1.7737,  1.7999,  1.8310,\n",
       "         1.8532,  1.8524,  1.6707,  1.6836,  1.8171,  1.8178,  1.8407,  1.8398,\n",
       "         1.8740,  1.8806,  1.8759,  1.9405,  1.9314,  1.9253,  1.9384,  1.9602,\n",
       "         1.9692,  2.0142,  2.0141,  2.0312,  2.0559,  2.0671,  2.0886,  2.1155,\n",
       "         2.1389,  2.1601,  2.1753,  2.1973,  2.2207,  2.2303,  2.2492,  2.2575,\n",
       "         2.1091,  2.1623,  2.2214,  2.2210,  2.2611,  2.2861,  2.2649,  2.2678,\n",
       "         2.2617,  2.2892,  2.2844,  2.2774,  2.2832,  2.2995,  2.2972,  1.9333,\n",
       "         2.3048,  2.3052,  2.3018,  2.2960,  2.2865,  2.2783,  2.2655,  2.2474,\n",
       "         2.2249,  2.1960,  2.1617,  2.1189,  2.0637,  1.9203,  1.9837,  1.9563,\n",
       "         1.9700,  1.9731,  1.8774,  1.9246,  1.9247,  1.9150,  1.9245,  1.9050,\n",
       "         1.8836,  1.8328,  1.7703,  1.7745,  1.7102,  1.6829,  1.5906,  1.5493,\n",
       "         1.5013,  1.4446,  1.3584,  1.2577,  1.1572,  1.0423,  0.9136,  0.7630,\n",
       "         0.5978,  0.4161,  0.2524,  0.0320, -0.8878, -0.0256, -0.0488, -0.1318,\n",
       "        -0.0942, -0.0478, -0.0124, -0.1251, -0.9925, -0.7879,  0.1482,  0.2474,\n",
       "         0.3165,  0.4518,  0.5636,  0.7138,  0.8446,  0.9777,  1.1343,  1.2897,\n",
       "         1.4499,  1.6290,  1.7711,  1.9369,  2.0700,  2.1615,  2.2634,  2.2769,\n",
       "         2.2443,  1.3281,  1.7084,  1.9053,  1.9506,  2.0414,  1.7799,  1.8706,\n",
       "         1.7483,  1.9511,  1.8761,  1.8383,  1.6587,  1.5686,  1.4777,  1.2070,\n",
       "         1.0238,  0.8400,  0.6178,  0.3794,  0.1656,  0.3884, -1.6804,  0.6045,\n",
       "         0.8498,  1.3685,  1.9112,  2.2924,  2.5911,  2.5512,  1.7530,  1.6683])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formfactor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3616,  1.7155, -1.3814, -0.2878, -0.9114])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0020])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bunch_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4532, -0.4376, -0.4221, -0.4059, -0.3925, -0.3846, -0.3829, -0.3856,\n",
       "        -0.3896, -0.3934, -0.3964, -0.3985, -0.3999, -0.4005, -0.4007, -0.4005,\n",
       "        -0.4002, -0.4000, -0.3998, -0.3997, -0.3998, -0.4000, -0.4004, -0.4008,\n",
       "        -0.4013, -0.4015, -0.4019, -0.4037, -0.4074, -0.4126, -0.4183, -0.4243,\n",
       "        -0.4309, -0.4379, -0.4454, -0.4532, -0.4611, -0.4690, -0.4769, -0.4847,\n",
       "        -0.4922, -0.4992, -0.5053, -0.5109, -0.5174, -0.5251, -0.5326, -0.5390,\n",
       "        -0.5442, -0.5495, -0.5561, -0.5640, -0.5720, -0.5795, -0.5863, -0.5925,\n",
       "        -0.5986, -0.6056, -0.6132, -0.6202, -0.6254, -0.6270, -0.6191, -0.5927,\n",
       "        -0.5399, -0.4538, -0.3326, -0.1847, -0.0210,  0.1518,  0.3331,  0.5266,\n",
       "         0.7321,  0.9510,  1.1886,  1.4529,  1.7598,  2.1348,  2.5822,  3.0652,\n",
       "         3.4982,  3.7927,  3.9313,  3.9726,  4.0022,  4.0659,  4.1547,  4.2426,\n",
       "         4.3249,  4.3937,  4.4215,  4.3959,  4.3457,  4.2917,  4.2158,  4.0946,\n",
       "         3.9514,  3.8225,  3.7079,  3.5867,  3.4532,  3.3099,  3.1694,  3.0557,\n",
       "         2.9746,  2.9051,  2.8194,  2.7018,  2.5561,  2.4017,  2.2581,  2.1447,\n",
       "         2.0801,  2.0720,  2.1067,  2.1486,  2.1505,  2.0881,  1.9713,  1.8359,\n",
       "         1.7282,  1.6745,  1.6778,  1.7232,  1.7774,  1.8069,  1.8024,  1.7797,\n",
       "         1.7557,  1.7236,  1.6751,  1.6241,  1.5815,  1.5364,  1.4884,  1.4679,\n",
       "         1.4965,  1.5676,  1.6521,  1.7100,  1.7249,  1.7177,  1.7107,  1.6953,\n",
       "         1.6597,  1.6152,  1.5786,  1.5575,  1.5610,  1.6003,  1.6648,  1.7279,\n",
       "         1.7637,  1.7662,  1.7495,  1.7463,  1.7902,  1.8794,  1.9721,  2.0216,\n",
       "         2.0128,  1.9533,  1.8551,  1.7426,  1.6368,  1.5421,  1.4674,  1.4188,\n",
       "         1.3756,  1.3139,  1.2306,  1.1324,  1.0083,  0.8366,  0.6071,  0.3368,\n",
       "         0.0548, -0.2003, -0.3942, -0.5172, -0.5870, -0.6258, -0.6435, -0.6424,\n",
       "        -0.6362, -0.6426, -0.6649, -0.6914, -0.7074, -0.7141, -0.7232, -0.7362,\n",
       "        -0.7420, -0.7369, -0.7243, -0.7088, -0.6976, -0.6962, -0.7018, -0.7107,\n",
       "        -0.7243, -0.7438, -0.7642, -0.7764, -0.7763, -0.7638, -0.7412, -0.7219,\n",
       "        -0.7222, -0.7367, -0.7443, -0.7370, -0.7240, -0.7162, -0.7137, -0.7145,\n",
       "        -0.7213, -0.7330, -0.7422, -0.7497, -0.7622, -0.7738, -0.7707, -0.7528,\n",
       "        -0.7359, -0.7292, -0.7272, -0.7242, -0.7222, -0.7243, -0.7274, -0.7245,\n",
       "        -0.7188, -0.7152, -0.7084, -0.6907, -0.6715, -0.6640, -0.6695, -0.6764,\n",
       "        -0.6742, -0.6624, -0.6531, -0.6574, -0.6725, -0.6854, -0.6885, -0.6840,\n",
       "        -0.6745, -0.6655, -0.6647, -0.6698, -0.6678, -0.6485, -0.6216, -0.6009,\n",
       "        -0.5884, -0.5741, -0.5593, -0.5559, -0.5645, -0.5642, -0.5413, -0.5036,\n",
       "        -0.4714, -0.4474, -0.4241, -0.4110, -0.4254, -0.4538, -0.4701, -0.4669,\n",
       "        -0.4540, -0.4372, -0.4193, -0.4005, -0.3813, -0.3617, -0.3419, -0.3223,\n",
       "        -0.3031, -0.2845, -0.2668, -0.2490, -0.2282, -0.2004, -0.1676, -0.1407,\n",
       "        -0.1291, -0.1322, -0.1355, -0.1303, -0.1259, -0.1333, -0.1381, -0.1209,\n",
       "        -0.0884, -0.0614, -0.0355, -0.0062])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<train_gan.EuXFELCurrentDataModule at 0x2a9df07c0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module = EuXFELCurrentDataModule(batch_size=64, normalize=True)\n",
    "data_module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.setup(stage=\"fit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x2a9df02e0>, 400)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = data_module.train_dataloader()\n",
    "data_loader, len(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x2a9df0b50>, 50)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = data_module.val_dataloader()\n",
    "data_loader, len(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x2a9df0520>, 50)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = data_module.test_dataloader()\n",
    "data_loader, len(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spectral-vd-euxfel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
